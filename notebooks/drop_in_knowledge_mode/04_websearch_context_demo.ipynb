{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4013d12",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Intergrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c664bf",
   "metadata": {},
   "source": [
    "# 04_websearch_context_demo.ipynb\n",
    "\n",
    "This notebook demonstrates how to use **DropInKnowledgeRuntime** with:\n",
    "\n",
    "- session-based chat,\n",
    "- optional RAG (attachments ingested into a vector store),\n",
    "- **live web search** via `WebSearchExecutor`,\n",
    "\n",
    "to achieve a \"ChatGPT-like\" experience with browsing.\n",
    "\n",
    "The core configuration (LLM adapter, embeddings, vector store, runtime config)\n",
    "is initialized in a single cell, while the rest of the notebook focuses on\n",
    "testing and inspecting the web search behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b1a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports and environment setup\n",
    "# --------------------------------\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LLM adapter (Ollama backend via LangChain)\n",
    "\n",
    "# Embeddings + vector store\n",
    "from intergrax.rag.embedding_manager import EmbeddingManager\n",
    "from intergrax.rag.vectorstore_manager import VSConfig, VectorstoreManager\n",
    "\n",
    "# Drop-in knowledge runtime pieces\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine.runtime import DropInKnowledgeRuntime\n",
    "from intergrax.runtime.drop_in_knowledge_mode.config import RuntimeConfig\n",
    "\n",
    "# Web search integration\n",
    "from intergrax.websearch.service.websearch_executor import WebSearchExecutor\n",
    "from intergrax.websearch.providers.google_cse_provider import GoogleCSEProvider\n",
    "# from intergrax.websearch.providers.bing_provider import BingWebProvider  # optional\n",
    "\n",
    "\n",
    "# 1.1 Load environment variables (API keys, etc.)\n",
    "load_dotenv()\n",
    "\n",
    "# Make sure the env vars for web search are available.\n",
    "# If you want to use Bing as well, uncomment the Bing provider later.\n",
    "os.environ[\"GOOGLE_CSE_API_KEY\"] = os.getenv(\"GOOGLE_CSE_API_KEY\") or \"\"\n",
    "os.environ[\"GOOGLE_CSE_CX\"] = os.getenv(\"GOOGLE_CSE_CX\") or \"\"\n",
    "os.environ[\"BING_SEARCH_V7_API_KEY\"] = os.getenv(\"BING_SEARCH_V7_API_KEY\") or \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162378b1",
   "metadata": {},
   "source": [
    "# Core runtime configuration (LLM + embeddings + vector store + web search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311a58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[intergraxVectorstoreManager] Initialized provider=chroma, collection=intergrax_docs_drop_in_demo\n",
      "[intergraxVectorstoreManager] Existing count: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<intergrax.runtime.drop_in_knowledge_mode.engine.runtime.DropInKnowledgeRuntime at 0x1f371685cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Core runtime configuration (LLM + embeddings + vector store + web search)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 2.1 Session store – simple in-memory storage for chat messages & metadata.\n",
    "from intergrax.globals.settings import GLOBAL_SETTINGS\n",
    "from intergrax.llm_adapters.base import LLMAdapterRegistry, LLMProvider\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.in_memory_session_storage import InMemorySessionStorage\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.session_manager import SessionManager\n",
    "\n",
    "\n",
    "session_manager = SessionManager(\n",
    "    storage=InMemorySessionStorage()\n",
    ")\n",
    "\n",
    "# 2.2 LLM adapter – here we use Ollama through the LangChain adapter.\n",
    "llm_adapter = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "\n",
    "# 2.3 Embedding manager – MUST match the model used during ingestion.\n",
    "embedding_manager = EmbeddingManager(\n",
    "    provider=\"ollama\",\n",
    "    model_name=GLOBAL_SETTINGS.default_ollama_embed_model,\n",
    "    assume_ollama_dim=1536,\n",
    ")\n",
    "\n",
    "# 2.4 Vector store configuration – same collection as in the RAG demo.\n",
    "vectorstore_cfg = VSConfig(\n",
    "    provider=\"chroma\",\n",
    "    collection_name=\"intergrax_docs_drop_in_demo\",\n",
    ")\n",
    "\n",
    "vectorstore_manager = VectorstoreManager(\n",
    "    config=vectorstore_cfg,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 2.5 Web search executor – wraps one or more providers (Google CSE, Bing, etc.)\n",
    "websearch_executor = WebSearchExecutor(\n",
    "    providers=[\n",
    "        GoogleCSEProvider(),\n",
    "    ],\n",
    "    max_text_chars=None,\n",
    ")\n",
    "\n",
    "# 2.6 RuntimeConfig – single source of truth for drop-in knowledge runtime.\n",
    "config = RuntimeConfig(\n",
    "    # LLM & embeddings & vector store\n",
    "    llm_adapter=llm_adapter,\n",
    "    embedding_manager=embedding_manager,\n",
    "    vectorstore_manager=vectorstore_manager,\n",
    "\n",
    "    # RAG settings (enabled to allow attachment-based context, as in 03 demo)\n",
    "    enable_rag=True,\n",
    "\n",
    "    # Web search settings – THIS is the feature under test in this notebook.\n",
    "    enable_websearch=True,\n",
    "    websearch_executor=websearch_executor,\n",
    "    max_docs_per_query=4,  # how many docs we inject into the system prompt\n",
    "\n",
    "    # Tools / memory – kept off here to isolate the web search behavior.\n",
    "    tools_mode=\"off\",\n",
    "    enable_user_profile_memory=True,\n",
    "\n",
    "    # Optional tenant / workspace (can be overridden per request)\n",
    "    tenant_id=\"demo-tenant\",\n",
    "    workspace_id=\"demo-workspace\",\n",
    ")\n",
    "\n",
    "# 2.7 Drop-in knowledge runtime – chat engine with RAG + web search.\n",
    "runtime = DropInKnowledgeRuntime(\n",
    "    config=config,\n",
    "    session_manager=session_manager,\n",
    ")\n",
    "\n",
    "runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc96fc4",
   "metadata": {},
   "source": [
    "### 3. Create a fresh chat session for this web search demo\n",
    "\n",
    "We create a brand new session in the in-memory store.\n",
    "All questions in this notebook will be sent under the same `session_id`\n",
    "so that the runtime can keep short-term chat history (like ChatGPT).\n",
    "\n",
    "Helper: `ask(question: str)` for interactive testing\n",
    "\n",
    "This helper:\n",
    "1. Builds a `RuntimeRequest` bound to the current session.\n",
    "2. Sends it through `DropInKnowledgeRuntime.ask(...)`.\n",
    "3. Prints:\n",
    "   - The user question\n",
    "   - The model answer (truncated optionally)\n",
    "   - Routing info (was RAG used? was web search used?)\n",
    "   - Basic debug info (web search, RAG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8d0301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created:\n",
      "- id: 66fc2d38-91ba-471a-9464-fe55b5625d7e\n",
      "- user_id: demo-user-websearch\n",
      "- tenant_id: demo-tenant\n",
      "- workspace_id: demo-workspace\n",
      "\n",
      "================================================================================\n",
      "USER QUESTION:\n",
      "Based on that, which framework would you recommend for a production-ready multi-agent system and why?\n",
      "================================================================================\n",
      "\n",
      "ASSISTANT ANSWER:\n",
      "\n",
      "Based on the provided search results, it's difficult to pinpoint a specific framework that would be recommended for a production-ready multi-agent system. However, I can try to infer some insights from the snippets:\n",
      "\n",
      "1. The first snippet mentions Robotec.ai, which seems to focus on developing production-ready autonomous systems. This implies that they may have experience with creating scalable and reliable multi-agent systems.\n",
      "2. The second snippet is about a control system controller called EClypse, which can be expanded to support up to 20 input/output (I/O) modules. While this doesn't directly relate to a framework for multi-agent systems, it does suggest that the manufacturer has experience with designing and implementing scalable and adaptable systems.\n",
      "3. The third snippet is about a research paper on the circular economy in the European photovoltaic industry. This seems unrelated to frameworks for multi-agent systems.\n",
      "4. The fourth snippet mentions Bartosz Walat's work as a creative director, which also doesn't appear to be relevant to multi-agent system development.\n",
      "\n",
      "Given this limited information, I would not recommend any specific framework from these search results. However, if I had to choose a potential candidate based on the emphasis on production-readiness and scalability (from snippets 1 and 2), I might consider looking into frameworks that are commonly used in robotics or autonomous systems, such as:\n",
      "\n",
      "* MADAM (Multi-Agent Development Environment) - a framework for building multi-agent systems\n",
      "* FAMA (Fuzzy Agent Framework) - a framework for developing fuzzy agent-based systems\n",
      "* SOAR (State, Operator, And Result) - an architecture for developing intelligent agents\n",
      "\n",
      "Please note that this is purely speculative, and I would recommend further research into the specific requirements of your project to determine the most suitable framework.\n",
      "\n",
      "--- ROUTING INFO ---\n",
      "strategy:           llm_with_websearch\n",
      "used_rag:           False\n",
      "used_websearch:     True\n",
      "used_tools:         False\n",
      "used_user_profile:  False\n",
      "\n",
      "--- DEBUG: RAG ---\n",
      "{\n",
      "  \"enabled\": true,\n",
      "  \"used\": false,\n",
      "  \"hits_count\": 0,\n",
      "  \"where_filter\": {\n",
      "    \"session_id\": \"66fc2d38-91ba-471a-9464-fe55b5625d7e\",\n",
      "    \"user_id\": \"demo-user-websearch\",\n",
      "    \"tenant_id\": \"demo-tenant\",\n",
      "    \"workspace_id\": \"demo-workspace\"\n",
      "  },\n",
      "  \"top_k\": 4,\n",
      "  \"score_threshold\": null,\n",
      "  \"hits\": []\n",
      "}\n",
      "\n",
      "--- DEBUG: WEBSEARCH ---\n",
      "{\n",
      "  \"num_docs\": 4,\n",
      "  \"top_urls\": [\n",
      "    \"https://pl.linkedin.com/company/robotec-ai\",\n",
      "    \"https://www.distech-controls.com/pl-pl/products/detail/947828/distech-controls/eclypse-connected-system-controller---ecy-csc-series\",\n",
      "    \"https://www.sciencedirect.com/science/article/pii/S0959652624008230\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RuntimeAnswer(answer=\"Based on the provided search results, it's difficult to pinpoint a specific framework that would be recommended for a production-ready multi-agent system. However, I can try to infer some insights from the snippets:\\n\\n1. The first snippet mentions Robotec.ai, which seems to focus on developing production-ready autonomous systems. This implies that they may have experience with creating scalable and reliable multi-agent systems.\\n2. The second snippet is about a control system controller called EClypse, which can be expanded to support up to 20 input/output (I/O) modules. While this doesn't directly relate to a framework for multi-agent systems, it does suggest that the manufacturer has experience with designing and implementing scalable and adaptable systems.\\n3. The third snippet is about a research paper on the circular economy in the European photovoltaic industry. This seems unrelated to frameworks for multi-agent systems.\\n4. The fourth snippet mentions Bartosz Walat's work as a creative director, which also doesn't appear to be relevant to multi-agent system development.\\n\\nGiven this limited information, I would not recommend any specific framework from these search results. However, if I had to choose a potential candidate based on the emphasis on production-readiness and scalability (from snippets 1 and 2), I might consider looking into frameworks that are commonly used in robotics or autonomous systems, such as:\\n\\n* MADAM (Multi-Agent Development Environment) - a framework for building multi-agent systems\\n* FAMA (Fuzzy Agent Framework) - a framework for developing fuzzy agent-based systems\\n* SOAR (State, Operator, And Result) - an architecture for developing intelligent agents\\n\\nPlease note that this is purely speculative, and I would recommend further research into the specific requirements of your project to determine the most suitable framework.\", citations=[], route=RouteInfo(used_rag=False, used_websearch=True, used_tools=False, used_user_profile=False, used_user_longterm_memory=False, strategy='llm_with_websearch', extra={}), tool_calls=[], stats=RuntimeStats(total_tokens=None, input_tokens=None, output_tokens=None, rag_tokens=None, websearch_tokens=None, tool_tokens=None, duration_ms=None, extra={}), raw_model_output=None, debug_trace={'session_id': '66fc2d38-91ba-471a-9464-fe55b5625d7e', 'user_id': 'demo-user-websearch', 'config': {'llm_label': 'default-llm', 'embedding_label': 'default-embedding', 'vectorstore_label': 'default-vectorstore'}, 'memory_layer': {'implemented': True, 'has_user_profile_instructions': False, 'has_org_profile_instructions': False, 'enable_user_profile_memory': True, 'enable_org_profile_memory': True}, 'steps': [{'timestamp': '2025-12-18T18:03:05.886249+00:00', 'component': 'engine', 'step': 'memory_layer', 'message': 'Profile-based instructions loaded for session.', 'data': {'has_user_profile_instructions': False, 'has_org_profile_instructions': False, 'enable_user_profile_memory': True, 'enable_org_profile_memory': True}}, {'timestamp': '2025-12-18T18:03:06.264162+00:00', 'component': 'engine', 'step': 'history', 'message': 'Conversation history built for LLM.', 'data': {'history_length': 1, 'base_history_length': 1, 'history_includes_current_user': True}}, {'timestamp': '2025-12-18T18:03:08.554438+00:00', 'component': 'engine', 'step': 'websearch', 'message': 'Web search step executed.', 'data': {'websearch_enabled': True, 'used_websearch': True, 'has_error': False}}, {'timestamp': '2025-12-18T18:03:18.879761+00:00', 'component': 'engine', 'step': 'core_llm', 'message': 'Core LLM adapter returned a plain string.', 'data': {'used_tools_answer': False, 'adapter_return_type': 'str'}}, {'timestamp': '2025-12-18T18:03:18.879761+00:00', 'component': 'engine', 'step': 'persist_and_build_answer', 'message': 'Assistant answer persisted and RuntimeAnswer built.', 'data': {'session_id': '66fc2d38-91ba-471a-9464-fe55b5625d7e', 'strategy': 'llm_with_websearch', 'used_rag': False, 'used_websearch': True, 'used_tools': False}}, {'timestamp': '2025-12-18T18:03:18.879761+00:00', 'component': 'engine', 'step': 'run_end', 'message': 'DropInKnowledgeRuntime.run() finished.', 'data': {'strategy': 'llm_with_websearch', 'used_rag': False, 'used_websearch': True, 'used_tools': False, 'used_user_longterm_memory': False}}], 'base_history_length': 1, 'history_tokens': {'raw_history_messages': 1, 'raw_history_tokens': 19, 'history_budget_tokens': 4096, 'strategy_requested': 'truncate_oldest', 'strategy_effective': 'truncate_oldest', 'truncated': False, 'summary_used': False, 'summary_tokens_budget': 0, 'tail_tokens_budget': 0}, 'history_length': 1, 'instructions': {'has_instructions': False, 'sources': {'request': False, 'user_profile': False, 'organization_profile': False}}, 'rag_chunks': 0, 'rag': {'enabled': True, 'used': False, 'hits_count': 0, 'where_filter': {'session_id': '66fc2d38-91ba-471a-9464-fe55b5625d7e', 'user_id': 'demo-user-websearch', 'tenant_id': 'demo-tenant', 'workspace_id': 'demo-workspace'}, 'top_k': 4, 'score_threshold': None, 'hits': []}, 'user_longterm_memory_hits': 0, 'user_longterm_memory': {}, 'websearch': {'num_docs': 4, 'top_urls': ['https://pl.linkedin.com/company/robotec-ai', 'https://www.distech-controls.com/pl-pl/products/detail/947828/distech-controls/eclypse-connected-system-controller---ecy-csc-series', 'https://www.sciencedirect.com/science/article/pii/S0959652624008230']}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "from intergrax.runtime.drop_in_knowledge_mode.responses.response_schema import RuntimeAnswer, RuntimeRequest\n",
    "\n",
    "# 3.1 Create a fresh session for this demo.\n",
    "session = await session_manager.create_session(\n",
    "    session_id=str(uuid.uuid4()),\n",
    "    user_id=\"demo-user-websearch\",\n",
    "    tenant_id=\"demo-tenant\",\n",
    "    workspace_id=\"demo-workspace\",\n",
    "    metadata={\"notebook\": \"04_websearch_drop_in_web_demo\"},\n",
    ")\n",
    "\n",
    "print(\"Session created:\")\n",
    "print(f\"- id: {session.id}\")\n",
    "print(f\"- user_id: {session.user_id}\")\n",
    "print(f\"- tenant_id: {session.tenant_id}\")\n",
    "print(f\"- workspace_id: {session.workspace_id}\")\n",
    "\n",
    "\n",
    "async def ask(question: str, *, show_full_answer: bool = True) -> RuntimeAnswer:\n",
    "    \"\"\"\n",
    "    Convenience helper for this notebook.\n",
    "\n",
    "    - Sends the user's question through DropInKnowledgeRuntime.\n",
    "    - Prints the answer and basic routing/debug information.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"USER QUESTION:\\n{question}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    request = RuntimeRequest(\n",
    "        session_id=session.id,\n",
    "        user_id=session.user_id,\n",
    "        tenant_id=session.tenant_id,\n",
    "        workspace_id=session.workspace_id,\n",
    "        message=question,\n",
    "        attachments=[],          # In this notebook we focus on web search (no files)\n",
    "        metadata={\"source\": \"04_websearch_demo\"},\n",
    "    )\n",
    "\n",
    "    answer = await runtime.run(request)\n",
    "\n",
    "    # 1) Print assistant answer\n",
    "    print(\"\\nASSISTANT ANSWER:\\n\")\n",
    "    if show_full_answer:\n",
    "        print(answer.answer)\n",
    "    else:\n",
    "        print(answer.answer[:700] + (\"...\" if len(answer.answer) > 700 else \"\"))\n",
    "\n",
    "    # 2) Routing information (did RAG / websearch fire?)\n",
    "    print(\"\\n--- ROUTING INFO ---\")\n",
    "    print(f\"strategy:           {answer.route.strategy}\")\n",
    "    print(f\"used_rag:           {answer.route.used_rag}\")\n",
    "    print(f\"used_websearch:     {answer.route.used_websearch}\")\n",
    "    print(f\"used_tools:         {answer.route.used_tools}\")\n",
    "    print(f\"used_user_profile:  {answer.route.used_user_profile}\")\n",
    "\n",
    "    # 3) Debug trace: show only relevant slices (websearch / rag)\n",
    "    debug = answer.debug_trace or {}\n",
    "\n",
    "    print(\"\\n--- DEBUG: RAG ---\")\n",
    "    rag_debug = debug.get(\"rag\")\n",
    "    if rag_debug:\n",
    "        print(json.dumps(rag_debug, indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"(no RAG debug info)\")\n",
    "\n",
    "    print(\"\\n--- DEBUG: WEBSEARCH ---\")\n",
    "    web_debug = debug.get(\"websearch\")\n",
    "    if web_debug:\n",
    "        print(json.dumps(web_debug, indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"(no websearch debug info)\")\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "answer_2 = await ask(\n",
    "    \"Based on that, which framework would you recommend for a production-ready multi-agent system and why?\"\n",
    ")\n",
    "\n",
    "answer_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
