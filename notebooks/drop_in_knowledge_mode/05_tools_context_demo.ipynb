{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d3c63b4",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Intergrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited.\n",
    "\n",
    "# 05_tools_context_demo.ipynb\n",
    "\n",
    "This notebook demonstrates how to use the **Drop-In Knowledge Runtime**\n",
    "with a **tools orchestration layer**, on top of:\n",
    "\n",
    "- conversational memory (chat history),\n",
    "- optional RAG (attachments ingested into a vector store),\n",
    "- optional live web search context.\n",
    "\n",
    "The focus of this notebook is to show **how tools are integrated and used\n",
    "in a ChatGPT-like flow**, while all other configuration (LLM, embeddings,\n",
    "vector store, web search) is pushed into a single compact setup cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29892419",
   "metadata": {},
   "source": [
    "## 1. Imports and environment setup\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "- configure the Python path so the `intergrax` package can be imported from the repo,\n",
    "- load environment variables (API keys, etc.),\n",
    "- import the core building blocks used by the Drop-In Knowledge Runtime.\n",
    "\n",
    "All non-tool configuration (LLM, embeddings, vector store, web search) will be\n",
    "initialized later in a **single compact config cell**, so that this notebook\n",
    "can stay focused on how the tools layer is integrated into the ChatGPT-like flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed63818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "RuntimeConfig ready.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from intergrax.llm_adapters.llm_provider import LLMProvider\n",
    "from intergrax.llm_adapters.llm_provider_registry import LLMAdapterRegistry\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine.runtime_context import RuntimeContext\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.in_memory_session_storage import InMemorySessionStorage\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.session_manager import SessionManager\n",
    "\n",
    "# --- Compact runtime configuration setup (all non-tools components) ---\n",
    "\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine.runtime import RuntimeEngine\n",
    "from intergrax.runtime.drop_in_knowledge_mode.config import RuntimeConfig\n",
    "\n",
    "\n",
    "\n",
    "# Core runtime configuration (LLM + embeddings + vector store + web search)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Session store – simple in-memory storage for chat messages & metadata.\n",
    "session_manager = SessionManager(\n",
    "   storage=InMemorySessionStorage() \n",
    ")\n",
    "\n",
    "# 2.2 LLM adapter – here we use Ollama through the LangChain adapter.\n",
    "llm_adapter = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "\n",
    "\n",
    "# RuntimeConfig – single source of truth for drop-in knowledge runtime.\n",
    "config = RuntimeConfig(\n",
    "    # LLM & embeddings & vector store\n",
    "    llm_adapter=llm_adapter,\n",
    "\n",
    "    # RAG settings (enabled to allow attachment-based context, as in 03 demo)\n",
    "    enable_rag=False,\n",
    "\n",
    "    # Web search settings – THIS is the feature under test in this notebook.\n",
    "    enable_websearch=False,\n",
    "\n",
    "    # Tools / memory – kept off here to isolate the web search behavior.    \n",
    "    enable_long_term_memory=False,\n",
    "    enable_user_profile_memory=True,\n",
    "\n",
    "    # Optional tenant / workspace (can be overridden per request)\n",
    "    tenant_id=\"demo-tenant\",\n",
    "    workspace_id=\"demo-workspace\",\n",
    "\n",
    "    tools_agent=None,            # set later\n",
    "    tools_mode=\"auto\"            # placeholder\n",
    ")\n",
    "\n",
    "context = RuntimeContext(\n",
    "    config=config,\n",
    "    session_manager=session_manager,\n",
    ")\n",
    "\n",
    "# Drop-in knowledge runtime – chat engine with RAG + web search.\n",
    "runtime = RuntimeEngine(context=context)\n",
    "\n",
    "print(\"RuntimeConfig ready.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226179d7",
   "metadata": {},
   "source": [
    "### 2.1 Defining tools using the Intergrax tools framework\n",
    "\n",
    "Instead of creating custom ad-hoc classes, we will reuse the existing\n",
    "Intergrax tools stack:\n",
    "\n",
    "- `ToolBase` & `ToolRegistry` for tool definitions and registration,\n",
    "- `IntergraxToolsAgent` as the planner/controller,\n",
    "- `ToolsAgentConfig` for agent behavior,\n",
    "- `IntergraxConversationalMemory` to keep dialogue context across calls.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Implement two demo tools (`WeatherTool`, `CalcTool`) exactly like in the\n",
    "   standalone tools notebook.\n",
    "2. Register them in a `ToolRegistry`.\n",
    "3. Create an `IntergraxToolsAgent` instance that uses an Ollama-based LLM.\n",
    "4. Attach this agent to `RuntimeConfig.tools_agent` so that the\n",
    "   Drop-In Knowledge Runtime can orchestrate tools in a ChatGPT-like flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c1366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntergraxToolsAgent attached to Drop-In Knowledge Runtime.\n"
     ]
    }
   ],
   "source": [
    "# --- Tools definitions and IntergraxToolsAgent wiring ---\n",
    "\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from intergrax.llm_adapters.llm_usage_track import LLMUsageTracker\n",
    "from intergrax.memory.conversational_memory import ConversationalMemory\n",
    "from intergrax.tools.tools_agent import ToolsAgent, ToolsAgentConfig\n",
    "from intergrax.tools.tools_base import ToolRegistry, ToolBase\n",
    "\n",
    "\n",
    "# ---------- WEATHER TOOL ----------\n",
    "\n",
    "class WeatherArgs(BaseModel):\n",
    "    \"\"\"\n",
    "    Argument schema for the weather tool.\n",
    "\n",
    "    Fields:\n",
    "      - city: name of the city for which we want to fetch weather information.\n",
    "    \"\"\"\n",
    "    city: str = Field(..., description=\"City name, e.g. 'Warsaw'\")\n",
    "\n",
    "\n",
    "class WeatherTool(ToolBase):\n",
    "    \"\"\"\n",
    "    Simple demo weather tool.\n",
    "\n",
    "    Responsibilities:\n",
    "      - Accept a city name.\n",
    "      - Return mock current weather information for that city.\n",
    "\n",
    "    NOTE:\n",
    "      In a real implementation this would call an external weather API.\n",
    "    \"\"\"\n",
    "    name = \"get_weather\"\n",
    "    description = (\n",
    "        \"Returns current weather for a city. \"\n",
    "        \"Use only for queries about weather, temperature or conditions in a city.\"\n",
    "    )\n",
    "    schema_model = WeatherArgs\n",
    "\n",
    "    def run(self, \n",
    "            run_id:Optional[str] = None,\n",
    "            llm_usage_tracker: Optional[LLMUsageTracker] = None,\n",
    "            **kwargs) -> Any:\n",
    "        city = kwargs[\"city\"]\n",
    "        # Demo output (static, not calling any real API).\n",
    "        return {\n",
    "            \"city\": city,\n",
    "            \"tempC\": 12.3,\n",
    "            \"summary\": \"partly cloudy (demo only, not real data)\",\n",
    "        }\n",
    "\n",
    "\n",
    "# ---------- CALCULATOR TOOL ----------\n",
    "\n",
    "class CalcArgs(BaseModel):\n",
    "    \"\"\"\n",
    "    Argument schema for the calculator tool.\n",
    "\n",
    "    Fields:\n",
    "      - expression: a simple arithmetic expression with numbers and operators.\n",
    "    \"\"\"\n",
    "    expression: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"A safe arithmetic expression to evaluate, \"\n",
    "            \"e.g. '235*17', '2*(3+4)'. No variables.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "class CalcTool(ToolBase):\n",
    "    \"\"\"\n",
    "    Basic arithmetic calculator tool.\n",
    "\n",
    "    Responsibilities:\n",
    "      - Validate a user-provided expression.\n",
    "      - Evaluate it using a restricted environment.\n",
    "      - Return both the expression and numeric result.\n",
    "    \"\"\"\n",
    "    name = \"calc_expression\"\n",
    "    description = (\n",
    "        \"Safely evaluates a basic arithmetic expression (integers/floats, + - * / parentheses). \"\n",
    "        \"Use for math and calculation questions.\"\n",
    "    )\n",
    "    schema_model = CalcArgs\n",
    "\n",
    "    def run(self, \n",
    "            run_id:Optional[str] = None,\n",
    "            llm_usage_tracker: Optional[LLMUsageTracker] = None,\n",
    "            **kwargs) -> Any:\n",
    "        expr = kwargs[\"expression\"]\n",
    "\n",
    "        # Minimal, safe evaluation – only allow basic numeric and operator characters.\n",
    "        allowed = \"0123456789.+-*/() \"\n",
    "        if not all(ch in allowed for ch in expr):\n",
    "            raise ValueError(\"Unsupported characters in expression.\")\n",
    "\n",
    "        # Perform the calculation in a restricted environment.\n",
    "        try:\n",
    "            result = eval(expr, {\"__builtins__\": {}}, {})\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Invalid expression: {e}\")\n",
    "\n",
    "        return {\"expression\": expr, \"result\": result}\n",
    "\n",
    "\n",
    "# ---------- TOOLS AGENT SETUP ----------\n",
    "\n",
    "# Conversational memory shared across tool-driven interactions.\n",
    "memory = ConversationalMemory()\n",
    "\n",
    "# Registry holding all available tools for the agent.\n",
    "tools_registry = ToolRegistry()\n",
    "tools_registry.register(WeatherTool())\n",
    "tools_registry.register(CalcTool())\n",
    "\n",
    "# LLM used as the planner / controller for tools.\n",
    "tools_llm = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "\n",
    "tools_agent = ToolsAgent(\n",
    "    llm=tools_llm,\n",
    "    tools=tools_registry,\n",
    "    memory=memory,\n",
    "    config=ToolsAgentConfig(),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Attach tools agent to the Drop-In Knowledge runtime configuration.\n",
    "config.tools_agent = tools_agent\n",
    "config.tools_mode = \"auto\"\n",
    "\n",
    "print(\"IntergraxToolsAgent attached to Drop-In Knowledge Runtime.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26937ffa",
   "metadata": {},
   "source": [
    "## 3. End-to-end Drop-In Runtime demo with tools\n",
    "\n",
    "Now that:\n",
    "\n",
    "- the runtime is configured (LLM + RAG + web search),\n",
    "- tools are defined and registered (`WeatherTool`, `CalcTool`),\n",
    "- `IntergraxToolsAgent` is attached to `RuntimeEngine.tools_agent`,\n",
    "\n",
    "we can run a **ChatGPT-like interaction** through the\n",
    "`DropInKnowledgeRuntime`.\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "1. Define a small helper function `ask_with_tools(...)` that:\n",
    "   - builds a `RuntimeRequest`,\n",
    "   - sends it to the runtime (`ask_sync`),\n",
    "   - prints the final answer and key debug information\n",
    "     (route, tools usage, tool call traces).\n",
    "2. Manually call this helper with different prompts:\n",
    "   - a weather question → `get_weather`,\n",
    "   - a math question → `calc_expression`,\n",
    "   - a mixed question where the LLM can decide whether tools are needed.\n",
    "\n",
    "This mirrors how tools are orchestrated in a ChatGPT-like flow:\n",
    "runtime decides when to call the tools agent, then the LLM integrates\n",
    "tool outputs into the final answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca40f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "async ask_with_tools helper is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Async helper for end-to-end testing of Drop-In Runtime with tools ---\n",
    "\n",
    "from pprint import pprint\n",
    "from intergrax.runtime.drop_in_knowledge_mode.responses.response_schema import RuntimeRequest\n",
    "\n",
    "\n",
    "async def ask_with_tools(\n",
    "    message: str,\n",
    "    *,\n",
    "    user_id: str = \"demo-user-tools\",\n",
    "    session_id: str = \"demo-session-tools\",\n",
    "):\n",
    "    \"\"\"\n",
    "    High-level async helper for interacting with the Drop-In Knowledge Runtime\n",
    "    in a ChatGPT-like way, with tools enabled (Jupyter / notebook friendly).\n",
    "\n",
    "    Steps:\n",
    "      1. Build a RuntimeRequest with the provided message.\n",
    "      2. Await runtime.ask(request).\n",
    "      3. Print:\n",
    "         - final model answer,\n",
    "         - routing info (which layers were used),\n",
    "         - tools debug trace,\n",
    "         - structured tool call summaries.\n",
    "    \"\"\"\n",
    "    request = RuntimeRequest(\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        message=message,\n",
    "    )\n",
    "\n",
    "    answer = await runtime.run(request)\n",
    "\n",
    "    print(\"=== ANSWER ===\")\n",
    "    print(answer.answer)\n",
    "\n",
    "    print(\"\\n=== ROUTE INFO ===\")\n",
    "    pprint(answer.route)\n",
    "\n",
    "    print(\"\\n=== TOOLS DEBUG TRACE ===\")\n",
    "    tools_debug = answer.debug_trace.get(\"tools\")\n",
    "    if tools_debug is not None:\n",
    "        pprint(tools_debug)\n",
    "    else:\n",
    "        print(\"No tools-specific debug information.\")\n",
    "\n",
    "    print(\"\\n=== TOOL CALLS (SUMMARY) ===\")\n",
    "    if answer.tool_calls:\n",
    "        pprint(answer.tool_calls)\n",
    "    else:\n",
    "        print(\"No tool calls were executed.\")\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "print(\"async ask_with_tools helper is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40afe32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[intergraxToolsAgent] Iteration 1 (planner)\n",
      "[intergraxToolsAgent] Calling tool: get_weather({'city': 'Warsaw'})\n",
      "[intergraxToolsAgent] Iteration 2 (planner)\n",
      "=== ANSWER ===\n",
      "The current weather in Warsaw is partly cloudy with a temperature of 12.3 degrees Celsius.\n",
      "\n",
      "=== ROUTE INFO ===\n",
      "RouteInfo(used_rag=False,\n",
      "          used_websearch=False,\n",
      "          used_tools=True,\n",
      "          used_long_term_memory=False,\n",
      "          used_user_profile=True,\n",
      "          strategy='llm_with_tools',\n",
      "          extra={})\n",
      "\n",
      "=== TOOLS DEBUG TRACE ===\n",
      "{'agent_answer_preview': 'The current weather in Warsaw is partly cloudy with '\n",
      "                         'a temperature of 12.3 degrees Celsius.',\n",
      " 'mode': 'auto',\n",
      " 'tool_traces': [{'args': {'city': 'Warsaw'},\n",
      "                  'output': {'city': 'Warsaw',\n",
      "                             'summary': 'partly cloudy (demo only, not real '\n",
      "                                        'data)',\n",
      "                             'tempC': 12.3},\n",
      "                  'output_preview': '{\"city\": \"Warsaw\", \"tempC\": 12.3, '\n",
      "                                    '\"summary\": \"partly cloudy (demo only, not '\n",
      "                                    'real data)\"}',\n",
      "                  'tool': 'get_weather'}],\n",
      " 'used_tools': True}\n",
      "\n",
      "=== TOOL CALLS (SUMMARY) ===\n",
      "[ToolCallInfo(tool_name='get_weather',\n",
      "              arguments={'city': 'Warsaw'},\n",
      "              result_summary='{\"city\": \"Warsaw\", \"tempC\": 12.3, \"summary\": '\n",
      "                             '\"partly cloudy (demo only, not real data)\"}',\n",
      "              success=True,\n",
      "              error_message=None,\n",
      "              extra={'raw_trace': {'args': {'city': 'Warsaw'},\n",
      "                                   'output': {'city': 'Warsaw',\n",
      "                                              'summary': 'partly cloudy (demo '\n",
      "                                                         'only, not real data)',\n",
      "                                              'tempC': 12.3},\n",
      "                                   'output_preview': '{\"city\": \"Warsaw\", '\n",
      "                                                     '\"tempC\": 12.3, '\n",
      "                                                     '\"summary\": \"partly '\n",
      "                                                     'cloudy (demo only, not '\n",
      "                                                     'real data)\"}',\n",
      "                                   'tool': 'get_weather'}})]\n",
      "[intergraxToolsAgent] Iteration 1 (planner)\n",
      "[intergraxToolsAgent] Calling tool: calc_expression({'expression': '235*17'})\n",
      "[intergraxToolsAgent] Iteration 2 (planner)\n",
      "=== ANSWER ===\n",
      "3995\n",
      "\n",
      "=== ROUTE INFO ===\n",
      "RouteInfo(used_rag=False,\n",
      "          used_websearch=False,\n",
      "          used_tools=True,\n",
      "          used_long_term_memory=False,\n",
      "          used_user_profile=True,\n",
      "          strategy='llm_with_tools',\n",
      "          extra={})\n",
      "\n",
      "=== TOOLS DEBUG TRACE ===\n",
      "{'agent_answer_preview': '3995',\n",
      " 'mode': 'auto',\n",
      " 'tool_traces': [{'args': {'expression': '235*17'},\n",
      "                  'output': {'expression': '235*17', 'result': 3995},\n",
      "                  'output_preview': '{\"expression\": \"235*17\", \"result\": 3995}',\n",
      "                  'tool': 'calc_expression'}],\n",
      " 'used_tools': True}\n",
      "\n",
      "=== TOOL CALLS (SUMMARY) ===\n",
      "[ToolCallInfo(tool_name='calc_expression',\n",
      "              arguments={'expression': '235*17'},\n",
      "              result_summary='{\"expression\": \"235*17\", \"result\": 3995}',\n",
      "              success=True,\n",
      "              error_message=None,\n",
      "              extra={'raw_trace': {'args': {'expression': '235*17'},\n",
      "                                   'output': {'expression': '235*17',\n",
      "                                              'result': 3995},\n",
      "                                   'output_preview': '{\"expression\": \"235*17\", '\n",
      "                                                     '\"result\": 3995}',\n",
      "                                   'tool': 'calc_expression'}})]\n",
      "[intergraxToolsAgent] Iteration 1 (planner)\n",
      "[intergraxToolsAgent] Calling tool: calc_expression({'expression': '235*17'})\n",
      "[intergraxToolsAgent] Iteration 2 (planner)\n",
      "=== ANSWER ===\n",
      "The current weather in Warsaw is partly cloudy with a temperature of 12.3 degrees Celsius.\n",
      "\n",
      "=== ROUTE INFO ===\n",
      "RouteInfo(used_rag=False,\n",
      "          used_websearch=False,\n",
      "          used_tools=True,\n",
      "          used_long_term_memory=False,\n",
      "          used_user_profile=True,\n",
      "          strategy='llm_with_tools',\n",
      "          extra={})\n",
      "\n",
      "=== TOOLS DEBUG TRACE ===\n",
      "{'agent_answer_preview': 'The current weather in Warsaw is partly cloudy with '\n",
      "                         'a temperature of 12.3 degrees Celsius.',\n",
      " 'mode': 'auto',\n",
      " 'tool_traces': [{'args': {'expression': '235*17'},\n",
      "                  'output': {'expression': '235*17', 'result': 3995},\n",
      "                  'output_preview': '{\"expression\": \"235*17\", \"result\": 3995}',\n",
      "                  'tool': 'calc_expression'}],\n",
      " 'used_tools': True}\n",
      "\n",
      "=== TOOL CALLS (SUMMARY) ===\n",
      "[ToolCallInfo(tool_name='calc_expression',\n",
      "              arguments={'expression': '235*17'},\n",
      "              result_summary='{\"expression\": \"235*17\", \"result\": 3995}',\n",
      "              success=True,\n",
      "              error_message=None,\n",
      "              extra={'raw_trace': {'args': {'expression': '235*17'},\n",
      "                                   'output': {'expression': '235*17',\n",
      "                                              'result': 3995},\n",
      "                                   'output_preview': '{\"expression\": \"235*17\", '\n",
      "                                                     '\"result\": 3995}',\n",
      "                                   'tool': 'calc_expression'}})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RuntimeAnswer(answer='The current weather in Warsaw is partly cloudy with a temperature of 12.3 degrees Celsius.', citations=[], route=RouteInfo(used_rag=False, used_websearch=False, used_tools=True, used_long_term_memory=False, used_user_profile=True, strategy='llm_with_tools', extra={}), tool_calls=[ToolCallInfo(tool_name='calc_expression', arguments={'expression': '235*17'}, result_summary='{\"expression\": \"235*17\", \"result\": 3995}', success=True, error_message=None, extra={'raw_trace': {'tool': 'calc_expression', 'args': {'expression': '235*17'}, 'output_preview': '{\"expression\": \"235*17\", \"result\": 3995}', 'output': {'expression': '235*17', 'result': 3995}}})], stats=RuntimeStats(total_tokens=None, input_tokens=None, output_tokens=None, rag_tokens=None, websearch_tokens=None, tool_tokens=None, duration_ms=None, extra={}), raw_model_output=None, debug_trace={'session_id': 'demo-session-tools', 'user_id': 'demo-user-tools', 'config': {'llm_label': 'llm-adapter-ollama', 'embedding_label': 'default-embedding', 'vectorstore_label': 'default-vectorstore'}, 'history_length': 5, 'tools': {'mode': 'auto', 'used_tools': True, 'tool_traces': [{'tool': 'calc_expression', 'args': {'expression': '235*17'}, 'output_preview': '{\"expression\": \"235*17\", \"result\": 3995}', 'output': {'expression': '235*17', 'result': 3995}}], 'agent_answer_preview': 'The current weather in Warsaw is partly cloudy with a temperature of 12.3 degrees Celsius.'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1: should trigger weather tool\n",
    "await ask_with_tools(\"What is the weather and temperature in Warsaw?\")\n",
    "\n",
    "# Example 2: should trigger calculator tool\n",
    "await ask_with_tools(\"Calculate 235*17 and give me only the numeric result.\")\n",
    "\n",
    "# Example 3: non-tool / mixed question\n",
    "await ask_with_tools(\"Explain how tools are integrated inside this runtime.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
