{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4952fb",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Intergrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3b2a6",
   "metadata": {},
   "source": [
    "# 07 — User Profile Instructions Baseline\n",
    "\n",
    "## Goal\n",
    "\n",
    "Introduce the first production-minimal user profile memory flow:\n",
    "\n",
    "**UserProfile → (profile.system_instructions) → runtime SYSTEM instructions**\n",
    "\n",
    "This notebook verifies that **user-level system instructions** can be resolved from the stored `UserProfile` and injected as the **first** `system` message in the runtime prompt.\n",
    "\n",
    "## Scope (baseline)\n",
    "\n",
    "- No RAG\n",
    "- No tools\n",
    "- No web search\n",
    "- No CoT / reasoning policies beyond default `DIRECT`\n",
    "- Strict typed fields (no `getattr`)\n",
    "- One cell at a time, production-ready wiring\n",
    "\n",
    "## What we will validate\n",
    "\n",
    "1. A `UserProfile` is persisted in the `UserProfileStore`.\n",
    "2. `SessionManager.get_user_profile_instructions_for_session()` resolves the user instructions string.\n",
    "3. `DropInKnowledgeRuntime` injects the final instructions as the first `system` message in `messages_for_llm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de423084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[intergraxVectorstoreManager] Initialized provider=chroma, collection=intergrax_docs\n",
      "[intergraxVectorstoreManager] Existing count: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "from intergrax.llm_adapters.llm_provider_registry import LLMAdapterRegistry\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine.runtime_context import RuntimeContext\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))\n",
    "\n",
    "# ==========================================================\n",
    "# RUNTIME CONFIGURATION (BASELINE: USER PROFILE INSTRUCTIONS)\n",
    "# ==========================================================\n",
    "\n",
    "from intergrax.llm_adapters.llm_provider import LLMProvider\n",
    "from intergrax.runtime.drop_in_knowledge_mode.config import RuntimeConfig\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine.runtime import RuntimeEngine\n",
    "\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.in_memory_session_storage import (\n",
    "    InMemorySessionStorage,\n",
    ")\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.session_manager import SessionManager\n",
    "\n",
    "from intergrax.memory.stores.in_memory_user_profile_store import InMemoryUserProfileStore\n",
    "from intergrax.memory.user_profile_manager import UserProfileManager\n",
    "from intergrax.memory.user_profile_memory import UserIdentity, UserPreferences, UserProfile\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Adapters / Backends\n",
    "# --------------------------\n",
    "\n",
    "llm_adapter = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Storage + Managers\n",
    "# --------------------------\n",
    "\n",
    "# Sessions (in-memory for notebook tests)\n",
    "session_storage = InMemorySessionStorage()\n",
    "\n",
    "# User profile (in-memory for notebook tests)\n",
    "user_profile_store = InMemoryUserProfileStore()\n",
    "user_profile_manager = UserProfileManager(store=user_profile_store)\n",
    "\n",
    "# Session manager (wired with user profile manager)\n",
    "session_manager = SessionManager(\n",
    "    storage=session_storage,\n",
    "    user_profile_manager=user_profile_manager,\n",
    "    organization_profile_manager=None,\n",
    "    session_memory_consolidation_service=None,\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Runtime Config (baseline)\n",
    "# --------------------------\n",
    "\n",
    "config = RuntimeConfig(\n",
    "    llm_adapter=llm_adapter,\n",
    "    enable_user_profile_memory=True,\n",
    "    enable_org_profile_memory=False,\n",
    "    enable_rag=False,\n",
    "    enable_websearch=False,\n",
    "    tools_mode=\"off\",\n",
    ")\n",
    "\n",
    "context = RuntimeContext(\n",
    "    config=config,\n",
    "    session_manager=session_manager,\n",
    "    ingestion_service=None,\n",
    "    context_builder=None,\n",
    "    rag_prompt_builder=None,\n",
    "    websearch_prompt_builder=None,\n",
    "    history_prompt_builder=None,\n",
    ")\n",
    "\n",
    "runtime = RuntimeEngine(context=context)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Test Data (stable IDs)\n",
    "# --------------------------\n",
    "\n",
    "USER_ID = \"user_test_07\"\n",
    "SESSION_ID = \"session_test_07\"\n",
    "\n",
    "# A minimal, explicit user profile whose system_instructions should be injected\n",
    "profile = UserProfile(\n",
    "    identity=UserIdentity(\n",
    "        user_id=USER_ID,\n",
    "        display_name=\"Artur\",\n",
    "        role=\"AI/LLM Systems Architect\",\n",
    "        domain_expertise=\"Intergrax runtime, memory layers, RAG/tool pipelines\",\n",
    "        language=\"en\",\n",
    "        locale=\"pl-PL\",\n",
    "        timezone=\"Europe/Warsaw\",\n",
    "    ),\n",
    "    preferences=UserPreferences(\n",
    "        preferred_language=\"en\",\n",
    "        answer_length=\"short\",\n",
    "        tone=\"technical\",\n",
    "        no_emojis_in_code=True,\n",
    "        no_emojis_in_docs=True,\n",
    "        prefer_markdown=True,\n",
    "        prefer_code_blocks=True,\n",
    "        default_project_context=\"Intergrax Drop-In Knowledge Runtime\",\n",
    "    ),\n",
    "    system_instructions=(\n",
    "        \"You are talking to Artur. Use a technical, concise style. \"\n",
    "        \"Never use emojis in code blocks or technical documentation. \"\n",
    "        \"Default project context: Intergrax Drop-In Knowledge Runtime.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Persist profile (baseline: instructions already exist, no LLM regeneration here)\n",
    "await user_profile_manager.save_profile(profile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9beba8c",
   "metadata": {},
   "source": [
    "## Step 2 — Run a baseline request and verify instruction injection\n",
    "\n",
    "In this step we will:\n",
    "\n",
    "1. Create a `RuntimeRequest` with `user_id` + `session_id`.\n",
    "2. Call `await runtime.run(request)`.\n",
    "3. Verify (via `answer.debug_trace[\"instructions\"]`) that the final `system` instructions were built **from user_profile**.\n",
    "4. Verify that the persisted session history contains **only user/assistant turns** (system instructions are not stored).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4dbcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANSWER ===\n",
      "Hello Artur. Based on our interaction history, I understand that you are engaged with the Intergrax Drop-In Knowledge Runtime (DIKR) project and prefer technical communication without emojis in code blocks or documentation.\n",
      "\n",
      "=== DEBUG: INSTRUCTIONS SOURCES ===\n",
      "{'has_instructions': True, 'sources': {'request': False, 'user_profile': True, 'organization_profile': False}}\n",
      "\n",
      "=== SESSION HISTORY (PERSISTED) ===\n",
      "History length: 2\n",
      "[0] role=user content='Say hello and summarize what you know about my preferences in one sentence.'\n",
      "[1] role=assistant content='Hello Artur. Based on our interaction history, I understand that you are engaged'\n"
     ]
    }
   ],
   "source": [
    "from intergrax.runtime.drop_in_knowledge_mode.responses.response_schema import RuntimeAnswer, RuntimeRequest\n",
    "\n",
    "# --------------------------\n",
    "# Run a baseline request\n",
    "# --------------------------\n",
    "\n",
    "request = RuntimeRequest(\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    "    message=\"Say hello and summarize what you know about my preferences in one sentence.\",\n",
    "    instructions=None,  # important: we want ONLY user_profile instructions in this baseline\n",
    ")\n",
    "\n",
    "answer : RuntimeAnswer = await runtime.run(request)\n",
    "\n",
    "print(\"=== ANSWER ===\")\n",
    "print(answer.answer)\n",
    "\n",
    "print(\"\\n=== DEBUG: INSTRUCTIONS SOURCES ===\")\n",
    "instructions_debug = answer.debug_trace.get(\"instructions\", {})\n",
    "print(instructions_debug)\n",
    "\n",
    "# Hard assertions for baseline:\n",
    "# - Instructions must exist\n",
    "# - They must come from user_profile (not request)\n",
    "assert instructions_debug.get(\"has_instructions\") is True, \"Expected instructions to be injected.\"\n",
    "sources = instructions_debug.get(\"sources\", {})\n",
    "assert sources.get(\"user_profile\") is True, \"Expected user_profile instructions source to be True.\"\n",
    "assert sources.get(\"request\") is not True, \"Expected request instructions source to be False/absent.\"\n",
    "\n",
    "# --------------------------\n",
    "# Verify persisted history does NOT contain system message\n",
    "# --------------------------\n",
    "\n",
    "history = await session_manager.get_history(session_id=SESSION_ID)\n",
    "\n",
    "print(\"\\n=== SESSION HISTORY (PERSISTED) ===\")\n",
    "print(f\"History length: {len(history)}\")\n",
    "for i, msg in enumerate(history):\n",
    "    print(f\"[{i}] role={msg.role} content={msg.content[:80]!r}\")\n",
    "\n",
    "assert len(history) >= 2, \"Expected at least user + assistant messages in persisted history.\"\n",
    "assert history[0].role == \"user\", \"First persisted message should be the user message.\"\n",
    "assert all(m.role != \"system\" for m in history), \"System instructions must not be persisted in session history.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a34aa",
   "metadata": {},
   "source": [
    "## Step 3 — Precedence test (request.instructions overrides user profile)\n",
    "\n",
    "Now we validate the **override rule**:\n",
    "\n",
    "- If `RuntimeRequest.instructions` is provided, it should take precedence over `UserProfile.system_instructions`.\n",
    "- `debug_trace[\"instructions\"][\"sources\"]` should indicate that `request=True`.\n",
    "- The model output should follow the request-level instruction even if it conflicts with the user profile.\n",
    "\n",
    "We also keep the same session to confirm that only user/assistant turns are persisted (no system messages).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f3f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANSWER (OVERRIDE) ===\n",
      "• Technical, concise communication\n",
      "• No use of emojis in code blocks or technical documentation\n",
      "\n",
      "=== DEBUG: INSTRUCTIONS SOURCES (OVERRIDE) ===\n",
      "{'has_instructions': True, 'sources': {'request': True, 'user_profile': True, 'organization_profile': False}}\n",
      "\n",
      "=== SESSION HISTORY (PERSISTED, AFTER OVERRIDE) ===\n",
      "History length: 4\n",
      "[0] role=user content=Say hello and summarize what you know about my preferences in one sentence.\n",
      "[1] role=assistant content=Hello Artur. Based on our interaction history, I understand that you are engaged with the Intergrax Drop-In Knowledge Runtime (DIKR) project and prefer technical communication without emojis in code blocks or documentation.\n",
      "[2] role=user content=Summarize my preferences now.\n",
      "[3] role=assistant content=• Technical, concise communication\n",
      "• No use of emojis in code blocks or technical documentation\n"
     ]
    }
   ],
   "source": [
    "from intergrax.runtime.drop_in_knowledge_mode.responses.response_schema import RuntimeAnswer, RuntimeRequest\n",
    "\n",
    "# --------------------------\n",
    "# Precedence test: request.instructions\n",
    "# --------------------------\n",
    "\n",
    "override_instructions = (\n",
    "    \"Reply in TWO bullet points only. \"\n",
    "    \"Do not greet. \"\n",
    "    \"Do not mention Intergrax.\"\n",
    ")\n",
    "\n",
    "request_override = RuntimeRequest(\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    "    message=\"Summarize my preferences now.\",\n",
    "    instructions=override_instructions,\n",
    ")\n",
    "\n",
    "answer_override: RuntimeAnswer = await runtime.run(request_override)\n",
    "\n",
    "print(\"=== ANSWER (OVERRIDE) ===\")\n",
    "print(answer_override.answer)\n",
    "\n",
    "print(\"\\n=== DEBUG: INSTRUCTIONS SOURCES (OVERRIDE) ===\")\n",
    "instructions_debug = answer_override.debug_trace.get(\"instructions\", {})\n",
    "print(instructions_debug)\n",
    "\n",
    "# Assertions:\n",
    "assert instructions_debug.get(\"has_instructions\") is True, \"Expected instructions to be injected.\"\n",
    "sources = instructions_debug.get(\"sources\", {})\n",
    "assert sources.get(\"request\") is True, \"Expected request instructions source to be True.\"\n",
    "\n",
    "# Behavior checks (lightweight, not brittle):\n",
    "# - should not contain a greeting 'Hello'\n",
    "# - should not mention 'Intergrax'\n",
    "assert \"Hello\" not in answer_override.answer, \"Expected no greeting due to request override.\"\n",
    "assert \"Intergrax\" not in answer_override.answer, \"Expected no Intergrax mention due to request override.\"\n",
    "\n",
    "# --------------------------\n",
    "# Verify persisted history still has no system messages\n",
    "# --------------------------\n",
    "\n",
    "history = await session_manager.get_history(session_id=SESSION_ID)\n",
    "\n",
    "print(\"\\n=== SESSION HISTORY (PERSISTED, AFTER OVERRIDE) ===\")\n",
    "print(f\"History length: {len(history)}\")\n",
    "for i, msg in enumerate(history):\n",
    "    print(f\"[{i}] role={msg.role} content={msg.content}\")\n",
    "\n",
    "assert all(m.role != \"system\" for m in history), \"System instructions must not be persisted in session history.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7cf36",
   "metadata": {},
   "source": [
    "## Step 4 — Explicit resolution path and per-session caching\n",
    "\n",
    "This final step makes the baseline flow explicit and verifiable:\n",
    "\n",
    "1. Load the persisted `ChatSession`.\n",
    "2. Call `SessionManager.get_user_profile_instructions_for_session(session)` directly.\n",
    "3. Verify:\n",
    "   - the returned string equals `UserProfile.system_instructions` (trimmed),\n",
    "   - the value is cached on the session (`session.user_profile_instructions`),\n",
    "   - the refresh flag is cleared (`session.needs_user_instructions_refresh == False`).\n",
    "\n",
    "This documents the *production-minimal* path used by the runtime:\n",
    "`UserProfile.system_instructions → (Session cached snapshot) → runtime system instructions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "917ade8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SESSION (BEFORE) ===\n",
      "user_profile_instructions: 'You are talking to Artur. Use a technical, concise style. Never use emojis in code blocks or technical documentation. Default project context: Intergrax Drop-In Knowledge Runtime.'\n",
      "needs_user_instructions_refresh: False\n",
      "\n",
      "=== SESSION (AFTER) ===\n",
      "resolved: 'You are talking to Artur. Use a technical, concise style. Never use emojis in code blocks or technical documentation. Default project context: Intergrax Drop-In Knowledge Runtime.'\n",
      "cached user_profile_instructions: 'You are talking to Artur. Use a technical, concise style. Never use emojis in code blocks or technical documentation. Default project context: Intergrax Drop-In Knowledge Runtime.'\n",
      "needs_user_instructions_refresh: False\n",
      "\n",
      "OK: UserProfile.system_instructions → cached per-session snapshot → runtime-ready instructions.\n"
     ]
    }
   ],
   "source": [
    "from intergrax.runtime.drop_in_knowledge_mode.session.chat_session import ChatSession\n",
    "\n",
    "# --------------------------\n",
    "# Load session created by previous runtime calls\n",
    "# --------------------------\n",
    "\n",
    "session: ChatSession = await session_manager.get_session(SESSION_ID)\n",
    "assert session is not None, \"Expected the session to exist after previous runtime.run() calls.\"\n",
    "assert session.user_id == USER_ID, \"Expected session.user_id to match the request user_id.\"\n",
    "\n",
    "print(\"=== SESSION (BEFORE) ===\")\n",
    "print(\"user_profile_instructions:\", repr(session.user_profile_instructions))\n",
    "print(\"needs_user_instructions_refresh:\", session.needs_user_instructions_refresh)\n",
    "\n",
    "# --------------------------\n",
    "# Explicit resolution (SessionManager -> UserProfileManager -> UserProfile.system_instructions)\n",
    "# --------------------------\n",
    "\n",
    "resolved = await session_manager.get_user_profile_instructions_for_session(session)\n",
    "assert isinstance(resolved, str) and resolved.strip(), \"Expected a non-empty resolved instructions string.\"\n",
    "\n",
    "expected = (profile.system_instructions or \"\").strip()\n",
    "assert resolved == expected, \"Resolved instructions must equal the stored UserProfile.system_instructions (trimmed).\"\n",
    "\n",
    "# Reload session to verify it was persisted with cached snapshot\n",
    "session_after: ChatSession = await session_manager.get_session(SESSION_ID)\n",
    "assert session_after is not None\n",
    "\n",
    "print(\"\\n=== SESSION (AFTER) ===\")\n",
    "print(\"resolved:\", repr(resolved))\n",
    "print(\"cached user_profile_instructions:\", repr(session_after.user_profile_instructions))\n",
    "print(\"needs_user_instructions_refresh:\", session_after.needs_user_instructions_refresh)\n",
    "\n",
    "assert session_after.user_profile_instructions == resolved, \"Expected resolved instructions to be cached on the session.\"\n",
    "assert session_after.needs_user_instructions_refresh is False, \"Expected refresh flag to be cleared after caching.\"\n",
    "\n",
    "print(\"\\nOK: UserProfile.system_instructions → cached per-session snapshot → runtime-ready instructions.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
