{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c942348",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Intergrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21db894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b1198",
   "metadata": {},
   "source": [
    "Basic sanity-check notebook for Drop-In Knowledge Mode runtime.\n",
    "\n",
    "Goals:\n",
    "  - Verify that DropInKnowledgeRuntime can:\n",
    "      * create or load a session,\n",
    "      * append user and assistant messages,\n",
    "      * build conversation history from SessionStore,\n",
    "      * return a RuntimeAnswer object.\n",
    "  - Use InMemorySessionStore for simplicity.\n",
    "  - Keep LLM integration as placeholder for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d9ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "from intergrax.runtime.drop_in_knowledge_mode.config import RuntimeConfig\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine import DropInKnowledgeRuntime\n",
    "from intergrax.runtime.drop_in_knowledge_mode.response_schema import RuntimeRequest\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session_store import (\n",
    "    InMemorySessionStore,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b92221",
   "metadata": {},
   "source": [
    "Create config, session store, runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3966c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[intergraxVectorstoreManager] Initialized provider=chroma, collection=intergrax_docs\n",
      "[intergraxVectorstoreManager] Existing count: 0\n",
      "Runtime initialized at 2025-11-21T11:24:54.596237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPS\\AppData\\Local\\Temp\\ipykernel_15552\\2928511357.py:58: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  print(\"Runtime initialized at\", datetime.utcnow().isoformat())\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from intergrax.llm_adapters import LangChainOllamaAdapter\n",
    "\n",
    "# Instantiate the in-memory session store\n",
    "session_store = InMemorySessionStore()\n",
    "\n",
    "# Instantiate a LLM adapter\n",
    "llm_adapter = LangChainOllamaAdapter(\n",
    "    chat = ChatOllama(\n",
    "        model = \"llama3.1:latest\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# For now we do not need real embedding/vectorstore managers for the skeleton;\n",
    "# if your RuntimeConfig requires concrete instances at import time, you can\n",
    "# inject the ones you already use in your RAG pipelines.\n",
    "from intergrax.rag.embedding_manager import IntergraxEmbeddingManager\n",
    "from intergrax.rag.vectorstore_manager import IntergraxVectorstoreManager, VSConfig\n",
    "\n",
    "# Example minimal initialization; adjust to your actual constructors/configs.\n",
    "embedding_manager = IntergraxEmbeddingManager(    \n",
    "    provider=\"ollama\",\n",
    "    model_name=\"rjmalagon/gte-qwen2-1.5b-instruct-embed-f16:latest\", \n",
    "    assume_ollama_dim=1536)\n",
    "\n",
    "\n",
    "TENANT = \"intergrax\"\n",
    "CORPUS = \"intergrax-strategy\"\n",
    "VERSION = \"v1\"\n",
    "\n",
    "# Initialize the vector store at startup (without loading/splitting/embedding yet).\n",
    "# This gives us a handle to the underlying database and allows for a light-weight\n",
    "# presence check before performing any expensive ingestion work.\n",
    "vectorstore_cfg = VSConfig(\n",
    "    provider=\"chroma\",\n",
    "    collection_name=\"intergrax_docs\"\n",
    ")\n",
    "\n",
    "vectorstore_manager = IntergraxVectorstoreManager(config=vectorstore_cfg, verbose=True)\n",
    "\n",
    "config = RuntimeConfig(\n",
    "    llm_adapter=llm_adapter,\n",
    "    embedding_manager=embedding_manager,\n",
    "    vectorstore_manager=vectorstore_manager,\n",
    "    llm_label=\"llm-adapter\",\n",
    "    embedding_label=\"default-embedding\",\n",
    "    vectorstore_label=\"default-vectorstore\",\n",
    "    enable_rag=False,        # disabled for this initial sanity check\n",
    "    enable_websearch=False,  # disabled for this initial sanity check\n",
    "    enable_tools=False,      # disabled for this initial sanity check\n",
    ")\n",
    "\n",
    "runtime = DropInKnowledgeRuntime(\n",
    "    config=config,\n",
    "    session_store=session_store,\n",
    ")\n",
    "\n",
    "print(\"Runtime initialized at\", datetime.utcnow().isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3fd97",
   "metadata": {},
   "source": [
    "First request: create a new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c456f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANSWER 1 ===\n",
      "Welcome to our Intergrax runtime environment.\n",
      "\n",
      "What brings you here today? Do you have any specific tasks or projects in mind that you'd like to work on, or would you like some suggestions on how to get started with the Intergrax platform?\n",
      "\n",
      "Route info:\n",
      "RouteInfo(used_rag=False,\n",
      "          used_websearch=False,\n",
      "          used_tools=False,\n",
      "          used_long_term_memory=False,\n",
      "          used_user_profile=True,\n",
      "          strategy='simple_placeholder',\n",
      "          extra={})\n",
      "\n",
      "Stats:\n",
      "RuntimeStats(total_tokens=None,\n",
      "             input_tokens=None,\n",
      "             output_tokens=None,\n",
      "             rag_tokens=None,\n",
      "             websearch_tokens=None,\n",
      "             tool_tokens=None,\n",
      "             duration_ms=None,\n",
      "             extra={})\n",
      "\n",
      "Debug trace:\n",
      "{'config': {'embedding_label': 'default-embedding',\n",
      "            'llm_label': 'llm-adapter',\n",
      "            'vectorstore_label': 'default-vectorstore'},\n",
      " 'history_length': 1,\n",
      " 'session_id': 'demo-session-001',\n",
      " 'user_id': 'demo-user-001'}\n"
     ]
    }
   ],
   "source": [
    "# Define user and session identifiers\n",
    "user_id = \"demo-user-001\"\n",
    "session_id = \"demo-session-001\"\n",
    "\n",
    "request_1 = RuntimeRequest(\n",
    "    user_id=user_id,\n",
    "    session_id=session_id,\n",
    "    message=\"Hello Intergrax runtime, this is my first message.\",\n",
    "    metadata={\"source\": \"notebook-demo\"},\n",
    ")\n",
    "\n",
    "answer_1 = await runtime.ask(request_1)\n",
    "\n",
    "print(\"=== ANSWER 1 ===\")\n",
    "print(answer_1.answer)\n",
    "print(\"\\nRoute info:\")\n",
    "pprint(answer_1.route)\n",
    "print(\"\\nStats:\")\n",
    "pprint(answer_1.stats)\n",
    "print(\"\\nDebug trace:\")\n",
    "pprint(answer_1.debug_trace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38286f",
   "metadata": {},
   "source": [
    "Inspect session state after first request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a001334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SESSION AFTER FIRST REQUEST ===\n",
      "Session ID: demo-session-001\n",
      "User ID: demo-user-001\n",
      "Messages count: 2\n",
      "Created at: 2025-11-21 11:24:54.601460+00:00\n",
      "Updated at: 2025-11-21 11:24:59.433174+00:00\n",
      "\n",
      "Messages:\n",
      "  [1] role='user', created_at=2025-11-21T11:24:54.601460+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [2] role='assistant', created_at=2025-11-21T11:24:59.433174+00:00\n",
      "      content=\"Welcome to our Intergrax runtime environment.\\n\\nWhat brings you here today? Do you have any specific tasks or projects in mind that you'd like to work on, or would you like some suggestions on how to get started with the Intergrax platform?\"\n"
     ]
    }
   ],
   "source": [
    "session = await session_store.get_session(answer_1.debug_trace[\"session_id\"])\n",
    "\n",
    "print(\"=== SESSION AFTER FIRST REQUEST ===\")\n",
    "print(\"Session ID:\", session.id)\n",
    "print(\"User ID:\", session.user_id)\n",
    "print(\"Messages count:\", len(session.messages))\n",
    "print(\"Created at:\", session.created_at)\n",
    "print(\"Updated at:\", session.updated_at)\n",
    "\n",
    "print(\"\\nMessages:\")\n",
    "for idx, msg in enumerate(session.messages, start=1):\n",
    "    print(f\"  [{idx}] role={msg.role!r}, created_at={msg.created_at.isoformat()}\")\n",
    "    print(f\"      content={msg.content!r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963297b9",
   "metadata": {},
   "source": [
    "Second request: same session, history should grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd54387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANSWER 2 ===\n",
      "So we're still going strong after your first message! Just for clarity, I should mention that this conversation just started, and there's no prior context or messages to recall from a previous session. But feel free to start fresh and ask me anything you'd like to know about Intergrax runtime or any other topic that interests you!\n",
      "\n",
      "Route info:\n",
      "RouteInfo(used_rag=False,\n",
      "          used_websearch=False,\n",
      "          used_tools=False,\n",
      "          used_long_term_memory=False,\n",
      "          used_user_profile=True,\n",
      "          strategy='simple_placeholder',\n",
      "          extra={})\n",
      "\n",
      "Debug trace:\n",
      "{'config': {'embedding_label': 'default-embedding',\n",
      "            'llm_label': 'llm-adapter',\n",
      "            'vectorstore_label': 'default-vectorstore'},\n",
      " 'history_length': 3,\n",
      " 'session_id': 'demo-session-001',\n",
      " 'user_id': 'demo-user-001'}\n",
      "\n",
      "=== SESSION AFTER SECOND REQUEST ===\n",
      "Session ID: demo-session-001\n",
      "Messages count: 4\n",
      "  [1] role='user', created_at=2025-11-21T11:24:54.601460+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [2] role='assistant', created_at=2025-11-21T11:24:59.433174+00:00\n",
      "      content=\"Welcome to our Intergrax runtime environment.\\n\\nWhat brings you here today? Do you have any specific tasks or projects in mind that you'd like to work on, or would you like some suggestions on how to get started with the Intergrax platform?\"\n",
      "  [3] role='user', created_at=2025-11-21T11:24:59.446306+00:00\n",
      "      content='This is my second message in the same session.'\n",
      "  [4] role='assistant', created_at=2025-11-21T11:25:01.244703+00:00\n",
      "      content=\"So we're still going strong after your first message! Just for clarity, I should mention that this conversation just started, and there's no prior context or messages to recall from a previous session. But feel free to start fresh and ask me anything you'd like to know about Intergrax runtime or any other topic that interests you!\"\n"
     ]
    }
   ],
   "source": [
    "request_2 = RuntimeRequest(\n",
    "    user_id=user_id,\n",
    "    session_id=session_id,\n",
    "    message=\"This is my second message in the same session.\",\n",
    "    metadata={\"source\": \"notebook-demo\"},\n",
    ")\n",
    "\n",
    "answer_2 = await runtime.ask(request_2)\n",
    "\n",
    "print(\"=== ANSWER 2 ===\")\n",
    "print(answer_2.answer)\n",
    "print(\"\\nRoute info:\")\n",
    "pprint(answer_2.route)\n",
    "print(\"\\nDebug trace:\")\n",
    "pprint(answer_2.debug_trace)\n",
    "\n",
    "session_2 = await session_store.get_session(answer_2.debug_trace[\"session_id\"])\n",
    "print(\"\\n=== SESSION AFTER SECOND REQUEST ===\")\n",
    "print(\"Session ID:\", session_2.id)\n",
    "print(\"Messages count:\", len(session_2.messages))\n",
    "for idx, msg in enumerate(session_2.messages, start=1):\n",
    "    print(f\"  [{idx}] role={msg.role!r}, created_at={msg.created_at.isoformat()}\")\n",
    "    print(f\"      content={msg.content!r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638b1f22",
   "metadata": {},
   "source": [
    "Verify that history length is limited by config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac31515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BUILT CHAT HISTORY ===\n",
      "History length: 4\n",
      "  [1] role='user', created_at=2025-11-21T11:24:54.601460+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [2] role='assistant', created_at=2025-11-21T11:24:59.433174+00:00\n",
      "      content=\"Welcome to our Intergrax runtime environment.\\n\\nWhat brings you here today? Do you have any specific tasks or projects in mind that you'd like to work on, or would you like some suggestions on how to get started with the Intergrax platform?\"\n",
      "  [3] role='user', created_at=2025-11-21T11:24:59.446306+00:00\n",
      "      content='This is my second message in the same session.'\n",
      "  [4] role='assistant', created_at=2025-11-21T11:25:01.244703+00:00\n",
      "      content=\"So we're still going strong after your first message! Just for clarity, I should mention that this conversation just started, and there's no prior context or messages to recall from a previous session. But feel free to start fresh and ask me anything you'd like to know about Intergrax runtime or any other topic that interests you!\"\n"
     ]
    }
   ],
   "source": [
    "from intergrax.llm.messages import ChatMessage\n",
    "\n",
    "# For debugging: call the history builder directly\n",
    "session_for_history = await session_store.get_session(answer_2.debug_trace[\"session_id\"])\n",
    "history = runtime._build_chat_history(session_for_history)\n",
    "\n",
    "print(\"=== BUILT CHAT HISTORY ===\")\n",
    "print(\"History length:\", len(history))\n",
    "for idx, msg in enumerate(history, start=1):\n",
    "    assert isinstance(msg, ChatMessage)\n",
    "    print(f\"  [{idx}] role={msg.role!r}, created_at={msg.created_at}\")\n",
    "    print(f\"      content={msg.content!r}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
