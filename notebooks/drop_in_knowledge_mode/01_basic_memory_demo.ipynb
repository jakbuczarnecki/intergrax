{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c942348",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Intergrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21db894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b1198",
   "metadata": {},
   "source": [
    "Basic sanity-check notebook for Drop-In Knowledge Mode runtime.\n",
    "\n",
    "Goals:\n",
    "  - Verify that DropInKnowledgeRuntime can:\n",
    "      * create or load a session,\n",
    "      * append user and assistant messages,\n",
    "      * build conversation history from SessionStore,\n",
    "      * return a RuntimeAnswer object.\n",
    "  - Use InMemorySessionStore for simplicity.\n",
    "  - Keep LLM integration as placeholder for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b92221",
   "metadata": {},
   "source": [
    "Create config, session store, runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3966c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime initialized at 2025-12-18T17:50:46.346770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPS\\AppData\\Local\\Temp\\ipykernel_3028\\2920471571.py:34: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  print(\"Runtime initialized at\", datetime.utcnow().isoformat())\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from intergrax.globals.settings import GLOBAL_SETTINGS\n",
    "from intergrax.llm_adapters.base import LLMAdapterRegistry, LLMProvider\n",
    "from intergrax.runtime.drop_in_knowledge_mode.config import RuntimeConfig\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine.runtime import DropInKnowledgeRuntime\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.in_memory_session_storage import InMemorySessionStorage\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.session_manager import SessionManager\n",
    "\n",
    "# Instantiate the in-memory session store\n",
    "session_manager = SessionManager(\n",
    "    storage=InMemorySessionStorage()\n",
    ")\n",
    "\n",
    "# Instantiate a LLM adapter\n",
    "llm_adapter = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "\n",
    "TENANT = \"intergrax\"\n",
    "CORPUS = \"intergrax-strategy\"\n",
    "VERSION = \"v1\"\n",
    "\n",
    "config = RuntimeConfig(\n",
    "    llm_adapter=llm_adapter,\n",
    "    llm_label=\"llm-adapter\",\n",
    "    enable_rag=False,        # disabled for this initial sanity check\n",
    "    enable_websearch=False,  # disabled for this initial sanity check\n",
    "    tools_mode=\"off\",      # disabled for this initial sanity check\n",
    ")\n",
    "\n",
    "runtime = DropInKnowledgeRuntime(\n",
    "    config=config,\n",
    "    session_manager=session_manager,\n",
    ")\n",
    "\n",
    "print(\"Runtime initialized at\", datetime.utcnow().isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3fd97",
   "metadata": {},
   "source": [
    "First request: create a new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c456f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANSWER 1 ===\n",
      "It looks like we've got a repeat of your initial message!\n",
      "\n",
      "Just to confirm, I'm not actually aware of the Integrax Runtime being a real platform or service. It's possible that it's a custom or internal system that you're familiar with.\n",
      "\n",
      "If you'd like to continue exploring the Integrax Runtime, could you please provide more context about what it is and how it works? I'll do my best to help you navigate its features and capabilities.\n",
      "\n",
      "Route info:\n",
      "RouteInfo(used_rag=False, used_websearch=False, used_tools=False, used_user_profile=False, used_user_longterm_memory=False, strategy='llm_only', extra={})\n",
      "\n",
      "Stats:\n",
      "RuntimeStats(total_tokens=None, input_tokens=None, output_tokens=None, rag_tokens=None, websearch_tokens=None, tool_tokens=None, duration_ms=None, extra={})\n",
      "\n",
      "Debug trace:\n",
      "{'session_id': 'demo-session-001', 'user_id': 'demo-user-001', 'config': {'llm_label': 'llm-adapter', 'embedding_label': 'default-embedding', 'vectorstore_label': 'default-vectorstore'}, 'memory_layer': {'implemented': True, 'has_user_profile_instructions': False, 'has_org_profile_instructions': False, 'enable_user_profile_memory': True, 'enable_org_profile_memory': True}, 'steps': [{'timestamp': '2025-12-18T17:51:10.513592+00:00', 'component': 'engine', 'step': 'memory_layer', 'message': 'Profile-based instructions loaded for session.', 'data': {'has_user_profile_instructions': False, 'has_org_profile_instructions': False, 'enable_user_profile_memory': True, 'enable_org_profile_memory': True}}, {'timestamp': '2025-12-18T17:51:10.513592+00:00', 'component': 'engine', 'step': 'history', 'message': 'Conversation history built for LLM.', 'data': {'history_length': 3, 'base_history_length': 3, 'history_includes_current_user': True}}, {'timestamp': '2025-12-18T17:51:12.946537+00:00', 'component': 'engine', 'step': 'core_llm', 'message': 'Core LLM adapter returned a plain string.', 'data': {'used_tools_answer': False, 'adapter_return_type': 'str'}}, {'timestamp': '2025-12-18T17:51:12.946537+00:00', 'component': 'engine', 'step': 'persist_and_build_answer', 'message': 'Assistant answer persisted and RuntimeAnswer built.', 'data': {'session_id': 'demo-session-001', 'strategy': 'llm_only', 'used_rag': False, 'used_websearch': False, 'used_tools': False}}, {'timestamp': '2025-12-18T17:51:12.946537+00:00', 'component': 'engine', 'step': 'run_end', 'message': 'DropInKnowledgeRuntime.run() finished.', 'data': {'strategy': 'llm_only', 'used_rag': False, 'used_websearch': False, 'used_tools': False, 'used_user_longterm_memory': False}}], 'base_history_length': 3, 'history_tokens': {'raw_history_messages': 3, 'raw_history_tokens': 112, 'history_budget_tokens': 4096, 'strategy_requested': 'truncate_oldest', 'strategy_effective': 'truncate_oldest', 'truncated': False, 'summary_used': False, 'summary_tokens_budget': 0, 'tail_tokens_budget': 0}, 'history_length': 3, 'instructions': {'has_instructions': False, 'sources': {'request': False, 'user_profile': False, 'organization_profile': False}}, 'rag_chunks': 0, 'user_longterm_memory_hits': 0, 'user_longterm_memory': {}}\n"
     ]
    }
   ],
   "source": [
    "# Define user and session identifiers\n",
    "import pprint\n",
    "from intergrax.runtime.drop_in_knowledge_mode.responses.response_schema import RuntimeRequest\n",
    "\n",
    "\n",
    "user_id = \"demo-user-001\"\n",
    "session_id = \"demo-session-001\"\n",
    "\n",
    "request_1 = RuntimeRequest(\n",
    "    user_id=user_id,\n",
    "    session_id=session_id,\n",
    "    message=\"Hello Intergrax runtime, this is my first message.\",\n",
    "    metadata={\"source\": \"notebook-demo\"},\n",
    ")\n",
    "\n",
    "answer_1 = await runtime.run(request_1)\n",
    "\n",
    "print(\"=== ANSWER 1 ===\")\n",
    "print(answer_1.answer)\n",
    "print(\"\\nRoute info:\")\n",
    "print(answer_1.route)\n",
    "print(\"\\nStats:\")\n",
    "print(answer_1.stats)\n",
    "print(\"\\nDebug trace:\")\n",
    "print(answer_1.debug_trace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38286f",
   "metadata": {},
   "source": [
    "Inspect session state after first request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a001334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SESSION AFTER FIRST REQUEST ===\n",
      "Session ID: demo-session-001\n",
      "User ID: demo-user-001\n",
      "Messages count: 4\n",
      "Created at: 2025-12-18 17:50:49.163095+00:00\n",
      "Updated at: 2025-12-18 17:51:12.946537+00:00\n",
      "\n",
      "Messages:\n",
      "  [1] role='user', created_at=2025-12-18T17:50:49.163095+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [2] role='assistant', created_at=2025-12-18T17:50:56.537793+00:00\n",
      "      content=\"Welcome to the Integrax Runtime! This is an exciting platform for integrating various services and applications.\\n\\nAs it appears that I'm not aware of your specific setup or environment, could you please provide more context about what you're trying to achieve with this platform? What kind of integrations are you planning, or what's the purpose behind using the Integrax Runtime in your project?\\n\\nI'm here to help and assist you throughout your integration journey.\"\n",
      "  [3] role='user', created_at=2025-12-18T17:51:10.513592+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [4] role='assistant', created_at=2025-12-18T17:51:12.946537+00:00\n",
      "      content=\"It looks like we've got a repeat of your initial message!\\n\\nJust to confirm, I'm not actually aware of the Integrax Runtime being a real platform or service. It's possible that it's a custom or internal system that you're familiar with.\\n\\nIf you'd like to continue exploring the Integrax Runtime, could you please provide more context about what it is and how it works? I'll do my best to help you navigate its features and capabilities.\"\n"
     ]
    }
   ],
   "source": [
    "session = await session_manager.get_session(answer_1.debug_trace[\"session_id\"])\n",
    "messages = await session_manager.get_history(session_id=answer_1.debug_trace[\"session_id\"])\n",
    "\n",
    "print(\"=== SESSION AFTER FIRST REQUEST ===\")\n",
    "print(\"Session ID:\", session.id)\n",
    "print(\"User ID:\", session.user_id)\n",
    "print(\"Messages count:\", len(messages))\n",
    "print(\"Created at:\", session.created_at)\n",
    "print(\"Updated at:\", session.updated_at)\n",
    "\n",
    "print(\"\\nMessages:\")\n",
    "for idx, msg in enumerate(messages, start=1):\n",
    "    print(f\"  [{idx}] role={msg.role!r}, created_at={msg.created_at}\")\n",
    "    print(f\"      content={msg.content!r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963297b9",
   "metadata": {},
   "source": [
    "Second request: same session, history should grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd54387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANSWER 2 ===\n",
      "It looks like you've sent another duplicate message!\n",
      "\n",
      "Just to confirm, our conversation has just started, and we haven't discussed anything yet. If you'd like to start fresh or ask a question about the Integrax Runtime (which I still don't have any information on), feel free to type something new.\n",
      "\n",
      "I'm here to help and provide assistance when needed!\n",
      "\n",
      "Route info:\n",
      "RouteInfo(used_rag=False, used_websearch=False, used_tools=False, used_user_profile=False, used_user_longterm_memory=False, strategy='llm_only', extra={})\n",
      "\n",
      "Debug trace:\n",
      "{'session_id': 'demo-session-001', 'user_id': 'demo-user-001', 'config': {'llm_label': 'llm-adapter', 'embedding_label': 'default-embedding', 'vectorstore_label': 'default-vectorstore'}, 'memory_layer': {'implemented': True, 'has_user_profile_instructions': False, 'has_org_profile_instructions': False, 'enable_user_profile_memory': True, 'enable_org_profile_memory': True}, 'steps': [{'timestamp': '2025-12-18T17:51:33.841745+00:00', 'component': 'engine', 'step': 'memory_layer', 'message': 'Profile-based instructions loaded for session.', 'data': {'has_user_profile_instructions': False, 'has_org_profile_instructions': False, 'enable_user_profile_memory': True, 'enable_org_profile_memory': True}}, {'timestamp': '2025-12-18T17:51:33.841745+00:00', 'component': 'engine', 'step': 'history', 'message': 'Conversation history built for LLM.', 'data': {'history_length': 7, 'base_history_length': 7, 'history_includes_current_user': True}}, {'timestamp': '2025-12-18T17:51:35.981747+00:00', 'component': 'engine', 'step': 'core_llm', 'message': 'Core LLM adapter returned a plain string.', 'data': {'used_tools_answer': False, 'adapter_return_type': 'str'}}, {'timestamp': '2025-12-18T17:51:35.981747+00:00', 'component': 'engine', 'step': 'persist_and_build_answer', 'message': 'Assistant answer persisted and RuntimeAnswer built.', 'data': {'session_id': 'demo-session-001', 'strategy': 'llm_only', 'used_rag': False, 'used_websearch': False, 'used_tools': False}}, {'timestamp': '2025-12-18T17:51:35.981747+00:00', 'component': 'engine', 'step': 'run_end', 'message': 'DropInKnowledgeRuntime.run() finished.', 'data': {'strategy': 'llm_only', 'used_rag': False, 'used_websearch': False, 'used_tools': False, 'used_user_longterm_memory': False}}], 'base_history_length': 7, 'history_tokens': {'raw_history_messages': 7, 'raw_history_tokens': 321, 'history_budget_tokens': 4096, 'strategy_requested': 'truncate_oldest', 'strategy_effective': 'truncate_oldest', 'truncated': False, 'summary_used': False, 'summary_tokens_budget': 0, 'tail_tokens_budget': 0}, 'history_length': 7, 'instructions': {'has_instructions': False, 'sources': {'request': False, 'user_profile': False, 'organization_profile': False}}, 'rag_chunks': 0, 'user_longterm_memory_hits': 0, 'user_longterm_memory': {}}\n",
      "\n",
      "=== SESSION AFTER SECOND REQUEST ===\n",
      "Session ID: demo-session-001\n",
      "Messages count: 8\n",
      "  [1] role='user', created_at=2025-12-18T17:50:49.163095+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [2] role='assistant', created_at=2025-12-18T17:50:56.537793+00:00\n",
      "      content=\"Welcome to the Integrax Runtime! This is an exciting platform for integrating various services and applications.\\n\\nAs it appears that I'm not aware of your specific setup or environment, could you please provide more context about what you're trying to achieve with this platform? What kind of integrations are you planning, or what's the purpose behind using the Integrax Runtime in your project?\\n\\nI'm here to help and assist you throughout your integration journey.\"\n",
      "  [3] role='user', created_at=2025-12-18T17:51:10.513592+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [4] role='assistant', created_at=2025-12-18T17:51:12.946537+00:00\n",
      "      content=\"It looks like we've got a repeat of your initial message!\\n\\nJust to confirm, I'm not actually aware of the Integrax Runtime being a real platform or service. It's possible that it's a custom or internal system that you're familiar with.\\n\\nIf you'd like to continue exploring the Integrax Runtime, could you please provide more context about what it is and how it works? I'll do my best to help you navigate its features and capabilities.\"\n",
      "  [5] role='user', created_at=2025-12-18T17:51:22.017214+00:00\n",
      "      content='This is my second message in the same session.'\n",
      "  [6] role='assistant', created_at=2025-12-18T17:51:24.554898+00:00\n",
      "      content=\"A new milestone! You've sent a second message in this conversation.\\n\\nSince we're still in the initial stages of our conversation, I don't have any specific context or information about your goals or requirements. If you'd like to share more about what brings you to the Integrax Runtime, I'm here to listen and help in any way I can.\\n\\nIf not, feel free to ask a question, request assistance with something specific, or simply continue the conversation for its own sake!\"\n",
      "  [7] role='user', created_at=2025-12-18T17:51:33.841745+00:00\n",
      "      content='This is my second message in the same session.'\n",
      "  [8] role='assistant', created_at=2025-12-18T17:51:35.981747+00:00\n",
      "      content=\"It looks like you've sent another duplicate message!\\n\\nJust to confirm, our conversation has just started, and we haven't discussed anything yet. If you'd like to start fresh or ask a question about the Integrax Runtime (which I still don't have any information on), feel free to type something new.\\n\\nI'm here to help and provide assistance when needed!\"\n"
     ]
    }
   ],
   "source": [
    "request_2 = RuntimeRequest(\n",
    "    user_id=user_id,\n",
    "    session_id=session_id,\n",
    "    message=\"This is my second message in the same session.\",\n",
    "    metadata={\"source\": \"notebook-demo\"},\n",
    ")\n",
    "\n",
    "answer_2 = await runtime.run(request_2)\n",
    "\n",
    "print(\"=== ANSWER 2 ===\")\n",
    "print(answer_2.answer)\n",
    "print(\"\\nRoute info:\")\n",
    "print(answer_2.route)\n",
    "print(\"\\nDebug trace:\")\n",
    "print(answer_2.debug_trace)\n",
    "\n",
    "session_2 = await session_manager.get_session(answer_2.debug_trace[\"session_id\"])\n",
    "messages = await session_manager.get_history(session_id=answer_1.debug_trace[\"session_id\"])\n",
    "\n",
    "print(\"\\n=== SESSION AFTER SECOND REQUEST ===\")\n",
    "print(\"Session ID:\", session_2.id)\n",
    "print(\"Messages count:\", len(messages))\n",
    "for idx, msg in enumerate(messages, start=1):\n",
    "    print(f\"  [{idx}] role={msg.role!r}, created_at={msg.created_at}\")\n",
    "    print(f\"      content={msg.content!r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638b1f22",
   "metadata": {},
   "source": [
    "Verify that history length is limited by config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac31515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BUILT CHAT HISTORY ===\n",
      "History length: 4\n",
      "  [1] role='user', created_at=2025-11-21T11:24:54.601460+00:00\n",
      "      content='Hello Intergrax runtime, this is my first message.'\n",
      "  [2] role='assistant', created_at=2025-11-21T11:24:59.433174+00:00\n",
      "      content=\"Welcome to our Intergrax runtime environment.\\n\\nWhat brings you here today? Do you have any specific tasks or projects in mind that you'd like to work on, or would you like some suggestions on how to get started with the Intergrax platform?\"\n",
      "  [3] role='user', created_at=2025-11-21T11:24:59.446306+00:00\n",
      "      content='This is my second message in the same session.'\n",
      "  [4] role='assistant', created_at=2025-11-21T11:25:01.244703+00:00\n",
      "      content=\"So we're still going strong after your first message! Just for clarity, I should mention that this conversation just started, and there's no prior context or messages to recall from a previous session. But feel free to start fresh and ask me anything you'd like to know about Intergrax runtime or any other topic that interests you!\"\n"
     ]
    }
   ],
   "source": [
    "from intergrax.llm.messages import ChatMessage\n",
    "\n",
    "# For debugging: call the history builder directly\n",
    "session_for_history = await session_manager.get_session(answer_2.debug_trace[\"session_id\"])\n",
    "history = await runtime._history_layer._build_chat_history(session_for_history)\n",
    "\n",
    "print(\"=== BUILT CHAT HISTORY ===\")\n",
    "print(\"History length:\", len(history))\n",
    "for idx, msg in enumerate(history, start=1):\n",
    "    assert isinstance(msg, ChatMessage)\n",
    "    print(f\"  [{idx}] role={msg.role!r}, created_at={msg.created_at}\")\n",
    "    print(f\"      content={msg.content!r}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
