{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c19374",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Intergrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3250b1e",
   "metadata": {},
   "source": [
    "# 03 – Drop-In Knowledge Mode: Context Builder (RAG) Demo\n",
    "\n",
    "This notebook demonstrates **how to wire the new `ContextBuilder` into the Drop-In Knowledge Mode runtime**, using only the minimal set of components that already exist in the Intergrax framework. :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "The goals of this notebook are:\n",
    "\n",
    "1. **Load a demo chat session**  \n",
    "   - Create or load a `ChatSession` using the existing `SessionStore`.\n",
    "   - Add a few example `ChatMessage` objects to simulate a short conversation.\n",
    "\n",
    "2. **Work with an existing attachment**  \n",
    "   - Use an attachment that has already been ingested (from the previous notebook `02_attachments_ingestion_demo.ipynb`), or prepare a single demo attachment (e.g. `PROJECT_STRUCTURE.md`) and ingest it using the existing ingestion pipeline.\n",
    "   - Make sure the attachment’s chunks are stored in the vector store with proper metadata (including `session_id` and `attachment_id`).\n",
    "\n",
    "3. **Initialize the `ContextBuilder`**  \n",
    "   - Construct a `ContextBuilder` instance using:\n",
    "     - the same `RuntimeConfig` as the Drop-In Knowledge Mode runtime,\n",
    "     - the shared `IntergraxVectorstoreManager`.\n",
    "   - Briefly explain the configuration knobs that affect RAG (e.g. `max_docs_per_query`, `max_history_messages`, optional score threshold).\n",
    "\n",
    "4. **Build context for a single user question**  \n",
    "   - Create a `RuntimeRequest` that represents the current user query.\n",
    "   - Call `ContextBuilder.build_context(session, request)` to obtain:\n",
    "     - reduced chat history,\n",
    "     - retrieved document chunks (RAG context),\n",
    "     - system prompt,\n",
    "     - RAG debug information.\n",
    "\n",
    "5. **Inspect the result of context building (no LLM call yet)**  \n",
    "   - Print and inspect:\n",
    "     - the reduced chat history selected by the `ContextBuilder`,\n",
    "     - the list of retrieved chunks (text, metadata, score),\n",
    "     - the internal RAG debug info (filters used, scores, etc.),\n",
    "     - the final system prompt that would be sent to the LLM.\n",
    "   - Optionally, show how these pieces can be turned into a list of messages for the LLM, but **without** modifying the main runtime engine yet.\n",
    "\n",
    "6. **Prepare for engine integration (next step)**  \n",
    "   - Clearly separate what is done in this notebook (manual usage of `ContextBuilder`) from what will be done in the next step:\n",
    "     - integrating `ContextBuilder` into `DropInKnowledgeRuntime.ask()`,\n",
    "     - wiring `rag_debug_info` into the runtime’s `debug_trace`.\n",
    "\n",
    "By the end of this notebook, we will have a **practical, end-to-end demonstration** of how the `ContextBuilder` uses:\n",
    "- session history,\n",
    "- RAG retrieval from the vector store,\n",
    "- and runtime configuration\n",
    "\n",
    "to produce a ready-to-use context object that the Drop-In Knowledge Mode engine can pass to any LLM adapter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b63108",
   "metadata": {},
   "source": [
    "## 1) Runtime Initialization\n",
    "\n",
    "This cell initializes the minimum set of components required to test the `ContextBuilder`.\n",
    "\n",
    "We are **not testing ingestion here** — attachments are assumed to be already ingested in the previous notebook (`02_attachments_ingestion_demo.ipynb`).\n",
    "\n",
    "Components initialized in this step:\n",
    "\n",
    "- In-memory session store\n",
    "- LLM adapter (Ollama-based)\n",
    "- Embedding manager (same model as ingestion pipeline)\n",
    "- Vector store manager (Chroma, same collection as before)\n",
    "- Runtime config (RAG will be enabled in the next cell)\n",
    "- Drop-In Knowledge runtime (used only as a dependency context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e860c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[intergraxVectorstoreManager] Initialized provider=chroma, collection=intergrax_docs_drop_in_demo\n",
      "[intergraxVectorstoreManager] Existing count: 100\n",
      "Runtime initialized at 2025-11-25T17:30:24.581366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XPS\\AppData\\Local\\Temp\\ipykernel_17444\\2805045218.py:67: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  print(\"Runtime initialized at\", datetime.utcnow().isoformat())\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "from intergrax.llm_adapters.llm_provider import LLMAdapterRegistry, LLMProvider\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))\n",
    "\n",
    "from intergrax.globals.settings import GLOBAL_SETTINGS\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.in_memory_session_storage import InMemorySessionStorage\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from intergrax.llm.messages import ChatMessage\n",
    "\n",
    "from intergrax.rag.embedding_manager import EmbeddingManager\n",
    "from intergrax.rag.vectorstore_manager import VectorstoreManager, VSConfig\n",
    "\n",
    "from intergrax.runtime.drop_in_knowledge_mode.config import RuntimeConfig\n",
    "from intergrax.runtime.drop_in_knowledge_mode.engine.runtime import DropInKnowledgeRuntime\n",
    "from intergrax.runtime.drop_in_knowledge_mode.session.session_manager import SessionManager\n",
    "\n",
    "\n",
    "# 1) Session store – temporary storage for chat messages and metadata\n",
    "session_manager = SessionManager(\n",
    "    storage=InMemorySessionStorage()\n",
    ")\n",
    "\n",
    "# 2) LLM adapter (Ollama backend)\n",
    "llm_adapter = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "\n",
    "# 3) Embedding manager (must match ingestion model)\n",
    "embedding_manager = EmbeddingManager(\n",
    "    provider=\"ollama\",\n",
    "    model_name=GLOBAL_SETTINGS.default_ollama_embed_model,\n",
    "    assume_ollama_dim=1536,\n",
    ")\n",
    "\n",
    "# 4) Vector store connection (same collection as ingestion)\n",
    "vectorstore_cfg = VSConfig(\n",
    "    provider=\"chroma\",\n",
    "    collection_name=\"intergrax_docs_drop_in_demo\",\n",
    ")\n",
    "\n",
    "vectorstore_manager = VectorstoreManager(\n",
    "    config=vectorstore_cfg,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 5) Runtime config – here we will enable RAG shortly\n",
    "config = RuntimeConfig(\n",
    "    llm_adapter=llm_adapter,\n",
    "    embedding_manager=embedding_manager,\n",
    "    vectorstore_manager=vectorstore_manager,\n",
    "    enable_rag=True,               # <-- ACTIVATED HERE (previous notebook had it off)\n",
    "    enable_websearch=False,\n",
    "    tools_mode=\"off\",\n",
    "    enable_user_profile_memory=True,\n",
    ")\n",
    "\n",
    "# 6) Drop-In Knowledge Mode runtime\n",
    "runtime = DropInKnowledgeRuntime(\n",
    "    config=config,\n",
    "    session_manager=session_manager,\n",
    ")\n",
    "\n",
    "print(\"Runtime initialized at\", datetime.utcnow().isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f693e",
   "metadata": {},
   "source": [
    "## 2) Prepare a demo chat session and minimal history\n",
    "\n",
    "In this step we:\n",
    "\n",
    "1. Create a new in-memory chat session for a demo user.\n",
    "2. Append a few simple messages to simulate an ongoing conversation.\n",
    "3. Verify that the session object contains:\n",
    "   - a `session_id` (or equivalent),\n",
    "   - `user_id`, `tenant_id`, `workspace_id`,\n",
    "   - a small list of `ChatMessage` objects.\n",
    "\n",
    "This session will later be passed to the `ContextBuilder` together with a `RuntimeRequest`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd532704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created session:\n",
      "  session_id : b087d6de-3cda-4d0e-a26d-f229fd657118\n",
      "  user_id    : demo-user-context-builder\n",
      "  tenant_id  : demo-tenant\n",
      "  workspace  : demo-workspace\n",
      "\n",
      "Session messages:\n",
      "- [user] Hi, I want to explore the Intergrax framework.\n",
      "- [assistant] Sure, I can help you with that.\n"
     ]
    }
   ],
   "source": [
    "# 2) Prepare a demo chat session and a minimal message history\n",
    "\n",
    "# NOTE:\n",
    "# The exact API of SessionStore may differ slightly in your codebase.\n",
    "# This example assumes a simple create_session(...) + get_session(...) + append_message(...) flow.\n",
    "# If your implementation uses different method names or signatures,\n",
    "# please adjust the calls below accordingly.\n",
    "\n",
    "# 2.1 Create a new session for a demo user\n",
    "demo_user_id = \"demo-user-context-builder\"\n",
    "demo_tenant_id = \"demo-tenant\"\n",
    "demo_workspace_id = \"demo-workspace\"\n",
    "\n",
    "session = await session_manager.create_session(\n",
    "    user_id=demo_user_id,\n",
    "    tenant_id=demo_tenant_id,\n",
    "    workspace_id=demo_workspace_id,\n",
    ")\n",
    "\n",
    "print(\"Created session:\")\n",
    "print(\"  session_id :\", getattr(session, \"session_id\", getattr(session, \"id\", \"<no-id-attr>\")))\n",
    "print(\"  user_id    :\", getattr(session, \"user_id\", None))\n",
    "print(\"  tenant_id  :\", getattr(session, \"tenant_id\", None))\n",
    "print(\"  workspace  :\", getattr(session, \"workspace_id\", None))\n",
    "\n",
    "# 2.2 Append a couple of messages to simulate conversation history\n",
    "await session_manager.append_message(\n",
    "    session_id=session.id,\n",
    "    message=ChatMessage(role=\"user\", content=\"Hi, I want to explore the Intergrax framework.\"),\n",
    ")\n",
    "\n",
    "await session_manager.append_message(\n",
    "    session_id=session.id,\n",
    "    message=ChatMessage(role=\"assistant\", content=\"Sure, I can help you with that.\"),\n",
    ")\n",
    "\n",
    "session = await session_manager.get_session(session.id)\n",
    "messages = await session_manager._storage.get_history(session_id=session.id)\n",
    "\n",
    "print(\"\\nSession messages:\")\n",
    "for msg in messages:\n",
    "    print(f\"- [{msg.role}] {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17665e",
   "metadata": {},
   "source": [
    "## 3) Initialize `ContextBuilder`, ingest the attachment for this session, and build context\n",
    "\n",
    "In this step we:\n",
    "\n",
    "1. Recreate the same `AttachmentRef` that was used in the ingestion demo  \n",
    "   (here: `PROJECT_STRUCTURE.md` at the repository root).\n",
    "2. Send a one-shot `RuntimeRequest` with this attachment to `DropInKnowledgeRuntime.ask(...)`  \n",
    "   so that:\n",
    "   - the engine stores a message with the attachment in the current session,\n",
    "   - the ingestion pipeline runs and upserts document chunks into the vector store\n",
    "     with this session's metadata.\n",
    "3. Initialize the `ContextBuilder` using the same `RuntimeConfig` and `VectorstoreManager`.\n",
    "4. Build context for a real user question using `ContextBuilder.build_context(session, request)`.\n",
    "\n",
    "The result will be stored in `built_context` and inspected in the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttachmentRef recreated:\n",
      "  id       : project-structure-md\n",
      "  type     : markdown\n",
      "  uri      : file:///D:/Projekty/intergrax/PROJECT_STRUCTURE.md\n",
      "\n",
      "Sending ingestion request to DropInKnowledgeRuntime...\n",
      "[intergraxVectorstoreManager] Upserting 100 items (dim=1536) to provider=chroma...\n",
      "[intergraxVectorstoreManager] Upsert complete. New count: 100\n",
      "Ingestion request completed.\n",
      "Answer summary: ok\n",
      "\n",
      "Session now has 4 message(s).\n",
      "\n",
      "ContextBuilder initialized.\n",
      "RuntimeRequest prepared.\n",
      "User query: Can you summarize the key components of the Intergrax architecture?\n",
      "\n",
      "Context built.\n",
      "RAG used        : True\n",
      "Chunks retrieved: 8\n"
     ]
    }
   ],
   "source": [
    "from intergrax.llm.messages import AttachmentRef\n",
    "from intergrax.runtime.drop_in_knowledge_mode.context.context_builder import BuiltContext, ContextBuilder\n",
    "from intergrax.runtime.drop_in_knowledge_mode.responses.response_schema import RuntimeRequest\n",
    "\n",
    "# 3.1 Recreate the attachment used in the ingestion demo (PROJECT_STRUCTURE.md)\n",
    "project_root_file = Path(\"../../PROJECT_STRUCTURE.md\").resolve()\n",
    "\n",
    "if not project_root_file.exists():\n",
    "    raise FileNotFoundError(f\"Expected demo file does not exist: {project_root_file}\")\n",
    "\n",
    "attachment_uri = project_root_file.as_uri()\n",
    "\n",
    "attachment = AttachmentRef(\n",
    "    id=\"project-structure-md\",\n",
    "    type=\"markdown\",\n",
    "    uri=attachment_uri,\n",
    "    metadata={\n",
    "        \"description\": \"Intergrax project structure document\",\n",
    "        \"scope\": \"intergrax-docs-demo\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"AttachmentRef recreated:\")\n",
    "print(\"  id       :\", attachment.id)\n",
    "print(\"  type     :\", attachment.type)\n",
    "print(\"  uri      :\", attachment.uri)\n",
    "\n",
    "\n",
    "# 3.2 Send a one-shot request with this attachment to the runtime\n",
    "# NOTE:\n",
    "# This call should:\n",
    "# - append a new user message (with the attachment) to the session,\n",
    "# - run the ingestion pipeline for THIS session,\n",
    "# - push vectors to the configured vector store with proper metadata.\n",
    "ingestion_request = RuntimeRequest(\n",
    "    session_id=session.id,\n",
    "    user_id=session.user_id,\n",
    "    tenant_id=session.tenant_id,\n",
    "    workspace_id=session.workspace_id,\n",
    "    message=\"Please index this attachment for the current session.\",\n",
    "    attachments=[attachment],\n",
    ")\n",
    "\n",
    "print(\"\\nSending ingestion request to DropInKnowledgeRuntime...\")\n",
    "ingestion_answer = await runtime.run(ingestion_request)\n",
    "print(\"Ingestion request completed.\")\n",
    "print(\"Answer summary:\", ingestion_answer.stats)\n",
    "\n",
    "\n",
    "# 3.3 Reload the session to ensure the new message (with attachment) is stored\n",
    "session = await session_manager.get_session(session.id)\n",
    "messages = await session_manager._storage.get_history(session_id=session.id)\n",
    "print(\"\\nSession now has\", len(messages), \"message(s).\")\n",
    "\n",
    "\n",
    "# 3.4 Initialize ContextBuilder (RAG is enabled in RuntimeConfig)\n",
    "context_builder = ContextBuilder(\n",
    "    vectorstore_manager=vectorstore_manager,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(\"\\nContextBuilder initialized.\")\n",
    "\n",
    "\n",
    "# 3.5 Create a RuntimeRequest representing the actual user question\n",
    "request = RuntimeRequest(\n",
    "    session_id=session.id,\n",
    "    user_id=session.user_id,\n",
    "    tenant_id=session.tenant_id,\n",
    "    workspace_id=session.workspace_id,\n",
    "    message=\"Can you summarize the key components of the Intergrax architecture?\",\n",
    ")\n",
    "\n",
    "print(\"RuntimeRequest prepared.\")\n",
    "print(\"User query:\", request.message)\n",
    "\n",
    "\n",
    "# 3.6 Build context using the current session + user question\n",
    "built_context : BuiltContext = await context_builder.build_context(\n",
    "    session=session,\n",
    "    request=request,\n",
    ")\n",
    "\n",
    "print(\"\\nContext built.\")\n",
    "print(\"RAG used        :\", built_context.rag_debug_info.get(\"used\"))\n",
    "print(\"Chunks retrieved:\", len(built_context.retrieved_chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ec84c8",
   "metadata": {},
   "source": [
    "## 4) Inspect the built context (history, retrieved chunks, debug info)\n",
    "\n",
    "Now that we have a `BuiltContext` instance, we want to inspect what the\n",
    "`ContextBuilder` actually produced:\n",
    "\n",
    "1. **System prompt** – the instruction that will be sent as the `system` message.\n",
    "2. **Reduced chat history** – messages that will be forwarded to the LLM.\n",
    "3. **Retrieved chunks (RAG context)** – text fragments loaded from the vector store.\n",
    "4. **RAG debug info** – internal diagnostics (filters used, scores, etc.).\n",
    "\n",
    "This step is purely diagnostic and does **not** call the LLM yet.\n",
    "It helps verify that the RAG layer is working as expected before we integrate\n",
    "it into `DropInKnowledgeRuntime.ask()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYSTEM PROMPT ===\n",
      "You are an AI assistant running in the Intergrax Drop-In Knowledge Mode.\n",
      "\n",
      "The runtime automatically:\n",
      "- receives and processes any user attachments (files),\n",
      "- splits them into chunks, indexes them in a vector store,\n",
      "- retrieves only the most relevant chunks for the current question.\n",
      "\n",
      "You see the final retrieved context as plain text snippets. You do NOT need to talk about indexing, vector stores, embeddings, or technical ingestion steps.\n",
      "\n",
      "Important behavior rules:\n",
      "1) Never say that you cannot see or access attachments. The runtime has already processed them for you.\n",
      "2) Never mention internal markers or identifiers from the retrieved context (such as IDs, scores, or file paths). They are for internal use only.\n",
      "3) Use the retrieved context when (and only when) it is relevant to the user's question.\n",
      "4) If the answer is not present in the retrieved context nor in the conversation history, say so explicitly instead of inventing details.\n",
      "5) Focus on the user's intent rather than on the mechanics of the system.\n",
      "6) If the user explicitly asks you to 'index', 'upload', 'attach', or 'remember' a file, assume that this has already been done by the runtime and simply confirm in one or two sentences that the file is indexed and now available as context. Do NOT explain ingestion modules, vector stores, or internal runtime components in your answer.\n",
      "\n",
      "\n",
      "\n",
      "=== REDUCED CHAT HISTORY ===\n",
      "[1] role=user\n",
      "Hi, I want to explore the Intergrax framework.\n",
      "------------------------------------------------------------\n",
      "[2] role=assistant\n",
      "Sure, I can help you with that.\n",
      "------------------------------------------------------------\n",
      "[3] role=user\n",
      "Please index this attachment for the current session.\n",
      "------------------------------------------------------------\n",
      "[4] role=assistant\n",
      "The file is already indexed and available as context for this session. You can proceed to ask questions or explore the Intergrax framework.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "=== RETRIEVED CHUNKS (RAG CONTEXT) ===\n",
      "Total retrieved chunks: 8\n",
      "\n",
      "--- CHUNK #1 ---\n",
      "ID    : project-structure-md-0\n",
      "Score : 0.8543816682619808\n",
      "Meta  : {'attachment_id': 'project-structure-md', 'chunk_total': 100, 'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md', 'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118', 'scope': 'intergrax-docs-demo', 'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md', 'chunk_index': 0, 'tenant_id': 'demo-tenant', 'workspace_id': 'demo-workspace', 'user_id': 'demo-user-context-builder', 'description': 'Intergrax project structure document', 'source_name': 'PROJECT_STRUCTURE.md', 'parent_id': 'd2a1abf5849e0ec1', 'ext': '.md', 'chunk_id': 'd2a1abf5849e0ec1#ch0000-109b5c6d', 'attachment_type': 'markdown'}\n",
      "\n",
      "TEXT PREVIEW:\n",
      "\n",
      "# Intergrax — Project Structure Overview\n",
      "\n",
      "This document was generated automatically by the Intergrax Project Structure Document Generator.\n",
      "\n",
      "## Purpose\n",
      "- Provide a clean overview of the current codebase structure.\n",
      "- Enable new developers to understand architectural roles quickly.\n",
      "- Serve as context for LLM agents (e.g., ChatGPT, Intergrax agents) to reason about and improve the project.\n",
      "\n",
      "## File Index\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- CHUNK #2 ---\n",
      "ID    : project-structure-md-41\n",
      "Score : 0.942800130350541\n",
      "Meta  : {'scope': 'intergrax-docs-demo', 'chunk_id': 'd2a1abf5849e0ec1#ch0041-d286f324', 'workspace_id': 'demo-workspace', 'parent_id': 'd2a1abf5849e0ec1', 'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118', 'attachment_id': 'project-structure-md', 'attachment_type': 'markdown', 'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md', 'tenant_id': 'demo-tenant', 'ext': '.md', 'source_name': 'PROJECT_STRUCTURE.md', 'chunk_total': 100, 'chunk_index': 41, 'description': 'Intergrax project structure document', 'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md', 'user_id': 'demo-user-context-builder'}\n",
      "\n",
      "TEXT PREVIEW:\n",
      "\n",
      "**Domain:** RAG logic\n",
      "\n",
      "**Key Responsibilities:**\n",
      "\n",
      "*   Splits documents into chunks based on pre-defined separators\n",
      "*   Generates stable chunk ids using available anchors (para_ix/row_ix/page_index) or falls back to index + hash of content\n",
      "*   Adds metadata to each chunk, including parent id, source name, and page index if present\n",
      "*   Merges tiny tails with previous chunks per document\n",
      "*   Applies optional hard cap on the number of chunks per document\n",
      "\n",
      "Note: The provided file appears to be a well\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- CHUNK #3 ---\n",
      "ID    : project-structure-md-96\n",
      "Score : 0.9462076298083205\n",
      "Meta  : {'parent_id': 'd2a1abf5849e0ec1', 'attachment_id': 'project-structure-md', 'chunk_index': 96, 'source_name': 'PROJECT_STRUCTURE.md', 'workspace_id': 'demo-workspace', 'user_id': 'demo-user-context-builder', 'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md', 'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118', 'attachment_type': 'markdown', 'description': 'Intergrax project structure document', 'chunk_id': 'd2a1abf5849e0ec1#ch0096-9cdd459c', 'scope': 'intergrax-docs-demo', 'tenant_id': 'demo-tenant', 'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md', 'ext': '.md', 'chunk_total': 100}\n",
      "\n",
      "TEXT PREVIEW:\n",
      "\n",
      "**Domain:** RAG logic / Agents\n",
      "\n",
      "**Key Responsibilities:**\n",
      "\n",
      "*   Defines a conversational memory for context tracking\n",
      "*   Registers and configures tools (e.g., WeatherTool, CalcTool)\n",
      "*   Sets up an LLM adapter (in this case, Ollama-backed) for reasoning and tool selection\n",
      "*   Initializes a tools agent that orchestrates LLM reasoning, tool invocation, and conversational memory updates\n",
      "*   Demonstrates the agent's functionality with two example queries\n",
      "\n",
      "### `notebooks\\supervisor\\supervisor_test.ipyn\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== RAG DEBUG INFO ===\n",
      "{'hits': [{'id': 'project-structure-md-0',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0000-109b5c6d',\n",
      "                        'chunk_index': 0,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': '# Intergrax — Project Structure Overview\\n'\n",
      "                      '\\n'\n",
      "                      'This document was generated automatically by the '\n",
      "                      'Intergrax Project Structure Document Generator.\\n'\n",
      "                      '\\n'\n",
      "                      '## Purpose\\n'\n",
      "                      '- Provide a clean overview of the current codebas',\n",
      "           'score': 0.8543816682619808},\n",
      "          {'id': 'project-structure-md-41',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0041-d286f324',\n",
      "                        'chunk_index': 41,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': '**Domain:** RAG logic\\n'\n",
      "                      '\\n'\n",
      "                      '**Key Responsibilities:**\\n'\n",
      "                      '\\n'\n",
      "                      '*   Splits documents into chunks based on pre-defined '\n",
      "                      'separators\\n'\n",
      "                      '*   Generates stable chunk ids using available anchors '\n",
      "                      '(para_ix/row_ix/page_index) or',\n",
      "           'score': 0.942800130350541},\n",
      "          {'id': 'project-structure-md-96',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0096-9cdd459c',\n",
      "                        'chunk_index': 96,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': '**Domain:** RAG logic / Agents\\n'\n",
      "                      '\\n'\n",
      "                      '**Key Responsibilities:**\\n'\n",
      "                      '\\n'\n",
      "                      '*   Defines a conversational memory for context '\n",
      "                      'tracking\\n'\n",
      "                      '*   Registers and configures tools (e.g., WeatherTool, '\n",
      "                      'CalcTool)\\n'\n",
      "                      '*   Sets up an LLM ',\n",
      "           'score': 0.9462076298083205},\n",
      "          {'id': 'project-structure-md-92',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0092-0185de29',\n",
      "                        'chunk_index': 92,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': '**Domain:** RAG logic\\n'\n",
      "                      '\\n'\n",
      "                      '**Key Responsibilities:**\\n'\n",
      "                      '\\n'\n",
      "                      '* Demonstrates how to load documents from a directory '\n",
      "                      'using `IntergraxDocumentsLoader` with various '\n",
      "                      'configuration options.\\n'\n",
      "                      '* Shows the process of spli',\n",
      "           'score': 0.9611874227177049},\n",
      "          {'id': 'project-structure-md-90',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0090-4f575859',\n",
      "                        'chunk_index': 90,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': 'Domain: LLM adapters, RAG logic, data ingestion, '\n",
      "                      'agents, configuration\\n'\n",
      "                      '\\n'\n",
      "                      'Key Responsibilities:\\n'\n",
      "                      '- Initializes LLM adapter for Ollama model\\n'\n",
      "                      '- Configures conversational memory\\n'\n",
      "                      '- Demonstrates usage of weat',\n",
      "           'score': 0.9649222467416536},\n",
      "          {'id': 'project-structure-md-42',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0042-a5df48b2',\n",
      "                        'chunk_index': 42,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': '**Domain:** RAG (Retrieval Augmented Generation) logic\\n'\n",
      "                      '\\n'\n",
      "                      '**Key Responsibilities:**\\n'\n",
      "                      '\\n'\n",
      "                      '*   Builds two vector indexes:\\n'\n",
      "                      '    *   Primary collection (`CHUNKS`): all '\n",
      "                      'chunks/documents after splitting\\n'\n",
      "                      '    *   Au',\n",
      "           'score': 0.9687320173098063},\n",
      "          {'id': 'project-structure-md-53',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0053-df527169',\n",
      "                        'chunk_index': 53,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': '**Domain:** RAG logic/configuration\\n'\n",
      "                      '\\n'\n",
      "                      '**Key Responsibilities:**\\n'\n",
      "                      '\\n'\n",
      "                      \"* Define main knobs for controlling the runtime's \"\n",
      "                      'behavior\\n'\n",
      "                      '* Integrate with existing Intergrax components (LLM '\n",
      "                      'adapters, embedding and v',\n",
      "           'score': 0.9742894723852276},\n",
      "          {'id': 'project-structure-md-40',\n",
      "           'metadata': {'attachment_id': 'project-structure-md',\n",
      "                        'attachment_type': 'markdown',\n",
      "                        'chunk_id': 'd2a1abf5849e0ec1#ch0040-c97ad860',\n",
      "                        'chunk_index': 40,\n",
      "                        'chunk_total': 100,\n",
      "                        'description': 'Intergrax project structure document',\n",
      "                        'ext': '.md',\n",
      "                        'parent_id': 'd2a1abf5849e0ec1',\n",
      "                        'scope': 'intergrax-docs-demo',\n",
      "                        'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                        'source': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'source_name': 'PROJECT_STRUCTURE.md',\n",
      "                        'source_path': 'D:\\\\Projekty\\\\intergrax\\\\PROJECT_STRUCTURE.md',\n",
      "                        'tenant_id': 'demo-tenant',\n",
      "                        'user_id': 'demo-user-context-builder',\n",
      "                        'workspace_id': 'demo-workspace'},\n",
      "           'preview': '**Domain:** Document Loaders\\n'\n",
      "                      '\\n'\n",
      "                      '**Key Responsibilities:**\\n'\n",
      "                      '\\n'\n",
      "                      '* Loading documents from various file formats (e.g., '\n",
      "                      '.txt, .docx, .pdf, .xlsx)\\n'\n",
      "                      '* Injecting metadata into loaded documents\\n'\n",
      "                      '* Handling images, in',\n",
      "           'score': 0.9839669468309863}],\n",
      " 'score_threshold': None,\n",
      " 'top_k': 8,\n",
      " 'used': True,\n",
      " 'where_filter': {'session_id': 'b087d6de-3cda-4d0e-a26d-f229fd657118',\n",
      "                  'tenant_id': 'demo-tenant',\n",
      "                  'user_id': 'demo-user-context-builder',\n",
      "                  'workspace_id': 'demo-workspace'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "messages = await session_manager._storage.get_history(session_id=session.id)\n",
    "\n",
    "# 4.1 Inspect reduced chat history\n",
    "print(\"=== REDUCED CHAT HISTORY ===\")\n",
    "if not messages:\n",
    "    print(\"(no history messages)\")\n",
    "else:\n",
    "    for i, msg in enumerate(messages, start=1):\n",
    "        print(f\"[{i}] role={msg.role}\")\n",
    "        print(msg.content)\n",
    "        print(\"-\" * 60)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 4.2 Inspect retrieved chunks (RAG context)\n",
    "print(\"=== RETRIEVED CHUNKS (RAG CONTEXT) ===\")\n",
    "chunks = built_context.retrieved_chunks\n",
    "\n",
    "print(f\"Total retrieved chunks: {len(chunks)}\\n\")\n",
    "\n",
    "if not chunks:\n",
    "    print(\"(no chunks retrieved - check if your vector store contains data and the metadata filters are correct)\")\n",
    "else:\n",
    "    max_preview = 3  # limit output for readability\n",
    "    for idx, ch in enumerate(chunks[:max_preview], start=1):\n",
    "        print(f\"--- CHUNK #{idx} ---\")\n",
    "        print(\"ID    :\", ch.id)\n",
    "        print(\"Score :\", ch.score)\n",
    "        print(\"Meta  :\", ch.metadata)\n",
    "        print(\"\\nTEXT PREVIEW:\\n\")\n",
    "        preview = ch.text[:500] if ch.text else \"\"\n",
    "        print(preview)\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "# 4.3 Inspect RAG debug info\n",
    "print(\"=== RAG DEBUG INFO ===\")\n",
    "pprint(built_context.rag_debug_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abdc39",
   "metadata": {},
   "source": [
    "## 5) One-shot ingestion for this session\n",
    "\n",
    "The vector store already contains data from previous experiments, but the\n",
    "`ContextBuilder` uses **session-scoped retrieval** (filters by `session_id`,\n",
    "`user_id`, etc.).\n",
    "\n",
    "To make RAG work for the **current** session, we need to:\n",
    "\n",
    "1. Recreate the same `AttachmentRef` as in the ingestion notebook\n",
    "   (e.g. for `PROJECT_STRUCTURE.md`).\n",
    "2. Send a `RuntimeRequest` with this attachment to `DropInKnowledgeRuntime.ask(...)`.\n",
    "   - The runtime will:\n",
    "     - store a user message with the attachment in the session,\n",
    "     - run the ingestion pipeline,\n",
    "     - push chunks to the vector store with this session’s metadata.\n",
    "\n",
    "We do this as a **single, compact step** – the goal of this notebook\n",
    "is still to test `ContextBuilder`, not to re-explain the ingestion pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c597eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttachmentRef recreated:\n",
      "  id       : project-structure-md\n",
      "  type     : markdown\n",
      "  uri      : file:///D:/Projekty/intergrax/PROJECT_STRUCTURE.md\n",
      "\n",
      "Sending ingestion request to DropInKnowledgeRuntime...\n",
      "[intergraxVectorstoreManager] Upserting 100 items (dim=1536) to provider=chroma...\n",
      "[intergraxVectorstoreManager] Upsert complete. New count: 100\n",
      "Ingestion request completed.\n",
      "Answer summary: ok\n",
      "\n",
      "Session now has 6 message(s).\n"
     ]
    }
   ],
   "source": [
    "from intergrax.llm.messages import AttachmentRef\n",
    "from intergrax.runtime.drop_in_knowledge_mode.responses.response_schema import RuntimeRequest\n",
    "\n",
    "# 5.1 Recreate the attachment used in the ingestion demo\n",
    "project_root_file = Path(\"../../PROJECT_STRUCTURE.md\").resolve()\n",
    "\n",
    "if not project_root_file.exists():\n",
    "    raise FileNotFoundError(f\"Expected demo file does not exist: {project_root_file}\")\n",
    "\n",
    "attachment_uri = project_root_file.as_uri()\n",
    "\n",
    "attachment = AttachmentRef(\n",
    "    id=\"project-structure-md\",\n",
    "    type=\"markdown\",\n",
    "    uri=attachment_uri,\n",
    "    metadata={\n",
    "        \"description\": \"Intergrax project structure document\",\n",
    "        \"scope\": \"intergrax-docs-demo\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"AttachmentRef recreated:\")\n",
    "print(\"  id       :\", attachment.id)\n",
    "print(\"  type     :\", attachment.type)\n",
    "print(\"  uri      :\", attachment.uri)\n",
    "\n",
    "\n",
    "# 5.2 Send a one-shot request with this attachment to the runtime\n",
    "# NOTE:\n",
    "# This call should trigger ingestion for THIS session:\n",
    "# - the engine stores the message + attachment in the session store,\n",
    "# - the ingestion service resolves the file, chunks it, embeds it,\n",
    "#   and upserts vectors into the configured vector store.\n",
    "\n",
    "ingestion_request = RuntimeRequest(\n",
    "    session_id=session.id,\n",
    "    user_id=session.user_id,\n",
    "    tenant_id=session.tenant_id,\n",
    "    workspace_id=session.workspace_id,\n",
    "    message=\"Please index this attachment for the current session.\",\n",
    "    attachments=[attachment],\n",
    ")\n",
    "\n",
    "print(\"\\nSending ingestion request to DropInKnowledgeRuntime...\")\n",
    "ingestion_answer = await runtime.run(ingestion_request)\n",
    "\n",
    "print(\"Ingestion request completed.\")\n",
    "print(\"Answer summary:\", ingestion_answer.status)\n",
    "\n",
    "# 5.3 Reload session to ensure the new message (with attachment) is stored\n",
    "session = await session_manager.get_session(session.id)\n",
    "messages = await session_manager.get_history(session_id=session.id)\n",
    "print(\"\\nSession now has\", len(messages), \"message(s).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
