{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73aec7c0",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Intergrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86670429",
   "metadata": {},
   "source": [
    "# Notebook 08 — User Profile Instructions Generation (LLM-based)\n",
    "\n",
    "## Goal\n",
    "Demonstrate a **production-safe, explicit** mechanism that **generates** `UserProfile.system_instructions` using an LLM, based on:\n",
    "- conversation history (user + assistant messages only),\n",
    "- existing user profile (current instructions),\n",
    "- (optionally) session metadata.\n",
    "\n",
    "## Non-goals (explicitly out of scope)\n",
    "- RAG / retrieval\n",
    "- tools\n",
    "- websearch\n",
    "- chain-of-thought or hidden reasoning frameworks\n",
    "- org-profile conflicts / precedence rules beyond baseline\n",
    "- runtime modifications (no changes to `ask()` flow)\n",
    "\n",
    "## Contract\n",
    "This notebook introduces a **separate, explicit \"profile consolidation\" flow**:\n",
    "\n",
    "history + existing profile\n",
    "    → LLM\n",
    "    → normalized instructions\n",
    "    → persist to UserProfile.system_instructions\n",
    "    → mark session as requiring refresh (`needs_user_instructions_refresh = True`)\n",
    "\n",
    "Runtime remains unchanged and will only **consume** the refreshed instructions snapshot (baseline proven in Notebook 07).\n",
    "\n",
    "## Source of truth\n",
    "All code and structure must follow the Intergrax bundle:\n",
    "- `INTERGRAX_ENGINE_BUNDLE.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9768839",
   "metadata": {},
   "source": [
    "## Conceptual Model — Profile Instructions Generation\n",
    "\n",
    "This notebook separates **instruction generation** from **instruction usage**.\n",
    "\n",
    "### Two distinct responsibilities\n",
    "\n",
    "**Runtime (Notebook 07)**\n",
    "- Uses `UserProfile.system_instructions`\n",
    "- Caches them at session level\n",
    "- Builds a runtime-only SYSTEM message\n",
    "- Never generates or mutates instructions\n",
    "\n",
    "**Profile Consolidation (Notebook 08)**\n",
    "- Generates `UserProfile.system_instructions`\n",
    "- Persists them to the user profile\n",
    "- Explicitly marks sessions as requiring refresh\n",
    "- Never participates in `ask()` execution\n",
    "\n",
    "### Data flow (explicit and one-directional)\n",
    "\n",
    "Conversation history (user + assistant only)\n",
    "Existing UserProfile.system_instructions\n",
    "(Optional) session metadata\n",
    "        ↓\n",
    "LLM-based consolidation\n",
    "        ↓\n",
    "Normalized system instructions (plain text)\n",
    "        ↓\n",
    "UserProfile.system_instructions (persisted)\n",
    "        ↓\n",
    "Session marked: needs_user_instructions_refresh = True\n",
    "\n",
    "### Key invariants\n",
    "\n",
    "- No system messages are read from or written to conversation history\n",
    "- No runtime code calls the LLM to generate instructions\n",
    "- No implicit refresh or auto-consolidation occurs\n",
    "- Consolidation is an explicit, auditable operation\n",
    "\n",
    "### Why this separation matters\n",
    "\n",
    "- Runtime stays deterministic and debuggable\n",
    "- Instruction generation can be tested, versioned, and audited independently\n",
    "- The system matches ChatGPT-like behavior:\n",
    "  instructions are **stable profile data**, not emergent runtime artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258e8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG READY\n",
      "- USER_ID: user_artur\n",
      "- SESSION_ID: sess_notebook08_001\n",
      "- Seeded profile.system_instructions and baseline-style history\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Protocol\n",
    "\n",
    "from intergrax.llm.messages import ChatMessage\n",
    "from intergrax.memory.stores.in_memory_user_profile_store import InMemoryUserProfileStore\n",
    "from intergrax.runtime.nexus.session.in_memory_session_storage import InMemorySessionStorage\n",
    "from intergrax.runtime.nexus.session.session_manager import SessionManager\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Test identifiers\n",
    "# ---------------------------------------------------------------------\n",
    "USER_ID: str = \"user_artur\"\n",
    "SESSION_ID: str = \"sess_notebook08_001\"\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Minimal LLM contract used by the generation service in this notebook.\n",
    "# (We keep it notebook-local and deterministic.)\n",
    "# ---------------------------------------------------------------------\n",
    "class InstructionsLLM(Protocol):\n",
    "    async def generate_user_profile_instructions(\n",
    "        self,\n",
    "        *,\n",
    "        existing_instructions: Optional[str],\n",
    "        history: List[ChatMessage],\n",
    "        metadata: Optional[dict] = None,\n",
    "        max_chars: int = 800,\n",
    "    ) -> str:\n",
    "        ...\n",
    "\n",
    "\n",
    "class FakeDeterministicInstructionsLLM:\n",
    "    \"\"\"\n",
    "    Deterministic LLM stub for Notebook 08.\n",
    "\n",
    "    Goal:\n",
    "      - Test the generation + persistence + session refresh flow\n",
    "      - Without relying on external APIs or model variability\n",
    "    \"\"\"\n",
    "\n",
    "    async def generate_user_profile_instructions(\n",
    "        self,\n",
    "        *,\n",
    "        existing_instructions: Optional[str],\n",
    "        history: List[ChatMessage],\n",
    "        metadata: Optional[dict] = None,\n",
    "        max_chars: int = 800,\n",
    "    ) -> str:\n",
    "        # NOTE: We deliberately avoid \"smart\" behavior here.\n",
    "        # We only reflect what Notebook 08 needs to validate.\n",
    "        base = (\n",
    "            \"You are talking to Artur. \"\n",
    "            \"Use a technical, concise style. \"\n",
    "            \"Never use emojis in code blocks or technical documentation. \"\n",
    "            \"Default project context: Intergrax nexus Runtime.\"\n",
    "        )\n",
    "\n",
    "        # A tiny, deterministic \"history signal\" to prove history was passed in.\n",
    "        # We only count user turns (role == 'user') and include it in output.\n",
    "        user_turns = 0\n",
    "        for m in history:\n",
    "            if m.role == \"user\":\n",
    "                user_turns += 1\n",
    "\n",
    "        suffix = f\" (history_user_turns={user_turns})\"\n",
    "        out = (base + suffix).strip()\n",
    "\n",
    "        if len(out) > max_chars:\n",
    "            out = out[:max_chars].rstrip()\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Notebook-local generation service\n",
    "#   history -> LLM -> profile.system_instructions\n",
    "#   + mark session needs_user_instructions_refresh=True\n",
    "# ---------------------------------------------------------------------\n",
    "@dataclass(frozen=True)\n",
    "class GenerationResult:\n",
    "    new_instructions: str\n",
    "    history_user_turns: int\n",
    "\n",
    "\n",
    "class UserProfileInstructionsGenerationService:\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        llm: InstructionsLLM,\n",
    "        user_profile_store: InMemoryUserProfileStore,\n",
    "        session_manager: SessionManager,\n",
    "    ) -> None:\n",
    "        self._llm = llm\n",
    "        self._user_profile_store = user_profile_store\n",
    "        self._session_manager = session_manager\n",
    "\n",
    "    async def generate_and_persist(\n",
    "        self,\n",
    "        *,\n",
    "        user_id: str,\n",
    "        session_id: str,\n",
    "        metadata: Optional[dict] = None,\n",
    "        max_chars: int = 800,\n",
    "    ) -> GenerationResult:\n",
    "        # 1) Load current profile\n",
    "        profile = await self._user_profile_store.get_profile(user_id)\n",
    "        existing = profile.system_instructions\n",
    "\n",
    "        # 2) Load conversation history (user+assistant only in baseline)\n",
    "        history = await self._session_manager.get_history_for_session(session_id)\n",
    "\n",
    "        # 3) Ask LLM to generate new instructions\n",
    "        new_instructions = await self._llm.generate_user_profile_instructions(\n",
    "            existing_instructions=existing,\n",
    "            history=history,\n",
    "            metadata=metadata,\n",
    "            max_chars=max_chars,\n",
    "        )\n",
    "\n",
    "        # 4) Persist to profile (domain data after generation)\n",
    "        profile.system_instructions = new_instructions\n",
    "        await self._user_profile_store.save_profile(profile)\n",
    "\n",
    "        # 5) Mark session refresh required (so runtime will re-snapshot later)\n",
    "        session = await self._session_manager.get_session(session_id)\n",
    "        if session is not None:\n",
    "            session.needs_user_instructions_refresh = True\n",
    "            await self._session_manager.save_session(session)\n",
    "\n",
    "        # For assertions / debugging\n",
    "        user_turns = 0\n",
    "        for m in history:\n",
    "            if m.role == \"user\":\n",
    "                user_turns += 1\n",
    "\n",
    "        return GenerationResult(new_instructions=new_instructions, history_user_turns=user_turns)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# In-memory infrastructure (stores + manager)\n",
    "# ---------------------------------------------------------------------\n",
    "session_storage = InMemorySessionStorage(max_history_messages=50)\n",
    "session_manager = SessionManager(storage=session_storage)\n",
    "\n",
    "user_profile_store = InMemoryUserProfileStore()\n",
    "\n",
    "llm = FakeDeterministicInstructionsLLM()\n",
    "generation_service = UserProfileInstructionsGenerationService(\n",
    "    llm=llm,\n",
    "    user_profile_store=user_profile_store,\n",
    "    session_manager=session_manager,\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Seed: create session + seed conversation history + seed an initial profile\n",
    "# ---------------------------------------------------------------------\n",
    "async def _seed() -> None:\n",
    "    # Create session\n",
    "    await session_manager.create_session(session_id=SESSION_ID, user_id=USER_ID)\n",
    "\n",
    "    # Seed baseline-style history (user/assistant only)\n",
    "    seed_messages: List[ChatMessage] = [\n",
    "        ChatMessage(role=\"user\", content=\"We are working on Intergrax nexus Runtime.\"),\n",
    "        ChatMessage(role=\"assistant\", content=\"Understood. I will keep it technical and concise.\"),\n",
    "        ChatMessage(role=\"user\", content=\"Never use emojis in code or technical docs.\"),\n",
    "        ChatMessage(role=\"assistant\", content=\"Acknowledged.\"),\n",
    "    ]\n",
    "\n",
    "    for msg in seed_messages:\n",
    "        await session_manager.append_message(SESSION_ID, msg)\n",
    "\n",
    "    # Seed initial profile instructions (simulate a pre-existing state)\n",
    "    profile = await user_profile_store.get_profile(USER_ID)\n",
    "    profile.system_instructions = (\n",
    "        \"You are talking to Artur. Use a technical, concise style.\"\n",
    "    )\n",
    "    await user_profile_store.save_profile(profile)\n",
    "\n",
    "\n",
    "await _seed()\n",
    "\n",
    "print(\"CONFIG READY\")\n",
    "print(f\"- USER_ID: {USER_ID}\")\n",
    "print(f\"- SESSION_ID: {SESSION_ID}\")\n",
    "print(\"- Seeded profile.system_instructions and baseline-style history\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d4e2a",
   "metadata": {},
   "source": [
    "# Cell 4 — Execute generation and validate persistence + session refresh\n",
    "#\n",
    "# What we validate in this cell:\n",
    "# 1) LLM-based instructions were generated using the session history\n",
    "# 2) UserProfile.system_instructions was updated (persisted)\n",
    "# 3) ChatSession.needs_user_instructions_refresh == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759652d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATION OK\n",
      "- before_instructions: 'You are talking to Artur. Use a technical, concise style.'\n",
      "- after_instructions : 'You are talking to Artur. Use a technical, concise style. Never use emojis in code blocks or technical documentation. Default project context: Intergrax nexus Runtime. (history_user_turns=2)'\n",
      "- before_refresh_flag: False\n",
      "- after_refresh_flag : True\n",
      "- history_user_turns : 2\n"
     ]
    }
   ],
   "source": [
    "async def _run_and_validate() -> None:\n",
    "    # --- Before snapshot ---\n",
    "    before_profile = await user_profile_store.get_profile(USER_ID)\n",
    "    before_session = await session_manager.get_session(SESSION_ID)\n",
    "\n",
    "    before_instr = before_profile.system_instructions\n",
    "    before_refresh_flag = before_session.needs_user_instructions_refresh if before_session else None\n",
    "\n",
    "    # --- Run generation ---\n",
    "    result = await generation_service.generate_and_persist(\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        metadata={\"notebook\": \"08\", \"purpose\": \"instructions_generation\"},\n",
    "        max_chars=800,\n",
    "    )\n",
    "\n",
    "    # --- After snapshot ---\n",
    "    after_profile = await user_profile_store.get_profile(USER_ID)\n",
    "    after_session = await session_manager.get_session(SESSION_ID)\n",
    "\n",
    "    after_instr = after_profile.system_instructions\n",
    "    after_refresh_flag = after_session.needs_user_instructions_refresh if after_session else None\n",
    "\n",
    "    # --- Assertions (hard checks) ---\n",
    "    assert after_instr is not None and after_instr.strip(), \"Expected non-empty generated instructions.\"\n",
    "    assert after_instr != (before_instr or \"\"), \"Expected instructions to change after generation.\"\n",
    "    assert after_refresh_flag is True, \"Expected session.needs_user_instructions_refresh to be True.\"\n",
    "\n",
    "    # We also validate that history was actually considered (our stub encodes it deterministically).\n",
    "    expected_suffix = f\"(history_user_turns={result.history_user_turns})\"\n",
    "    assert expected_suffix in after_instr, \"Expected generated instructions to include the history signal.\"\n",
    "\n",
    "    # --- Print summary ---\n",
    "    print(\"GENERATION OK\")\n",
    "    print(f\"- before_instructions: {before_instr!r}\")\n",
    "    print(f\"- after_instructions : {after_instr!r}\")\n",
    "    print(f\"- before_refresh_flag: {before_refresh_flag}\")\n",
    "    print(f\"- after_refresh_flag : {after_refresh_flag}\")\n",
    "    print(f\"- history_user_turns : {result.history_user_turns}\")\n",
    "\n",
    "\n",
    "await _run_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5945d",
   "metadata": {},
   "source": [
    "# Cell 6 — Explicit session refresh and snapshot validation\n",
    "#\n",
    "# Purpose:\n",
    "# Prove that after consolidation:\n",
    "# - the session is refreshed,\n",
    "# - a new user_profile_instructions snapshot is available at session level,\n",
    "# - WITHOUT calling runtime ask() or mutating conversation history.\n",
    "#\n",
    "# This mirrors the baseline behavior proven in Notebook 07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6b3f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFRESH OK\n",
      "- session snapshot updated via get_user_profile_instructions_for_session(session)\n",
      "- refresh flag cleared\n",
      "- history unchanged (user/assistant only)\n",
      "- snapshot value:\n",
      "You are talking to Artur. Use a technical, concise style. Never use emojis in code blocks or technical documentation. Default project context: Intergrax nexus Runtime. (history_user_turns=2)\n"
     ]
    }
   ],
   "source": [
    "from intergrax.memory.user_profile_manager import UserProfileManager\n",
    "\n",
    "async def _refresh_and_validate_snapshot() -> None:\n",
    "    # Load session\n",
    "    session_before = await session_manager.get_session(SESSION_ID)\n",
    "    assert session_before is not None, \"Session not found.\"\n",
    "\n",
    "    # Ensure SessionManager can resolve user-level instructions.\n",
    "    # get_user_profile_instructions_for_session() requires a configured UserProfileManager.\n",
    "    effective_session_manager = session_manager\n",
    "    if effective_session_manager._user_profile_manager is None:\n",
    "        effective_session_manager = SessionManager(\n",
    "            storage=session_storage,\n",
    "            user_profile_manager=UserProfileManager(user_profile_store),\n",
    "        )\n",
    "\n",
    "    # Force refresh request (do NOT assume flag state from previous cells).\n",
    "    session_before.needs_user_instructions_refresh = True\n",
    "    await effective_session_manager.save_session(session_before)\n",
    "\n",
    "    # Run \"lazy refresh\" path:\n",
    "    # - resolve from UserProfileManager.get_system_instructions_for_user(user_id)\n",
    "    # - cache on session.user_profile_instructions\n",
    "    # - clear needs_user_instructions_refresh\n",
    "    refreshed = await effective_session_manager.get_user_profile_instructions_for_session(\n",
    "        session_before\n",
    "    )\n",
    "    assert isinstance(refreshed, str) and refreshed.strip(), (\n",
    "        \"Expected a non-empty instructions string after refresh.\"\n",
    "    )\n",
    "\n",
    "    # Post-refresh snapshots\n",
    "    session_after = await effective_session_manager.get_session(SESSION_ID)\n",
    "    assert session_after is not None, \"Session not found after refresh.\"\n",
    "\n",
    "    profile_after = await user_profile_store.get_profile(USER_ID)\n",
    "\n",
    "    # Assertions (snapshot + flags)\n",
    "    assert session_after.needs_user_instructions_refresh is False, (\n",
    "        \"Expected refresh flag to be cleared after snapshot refresh.\"\n",
    "    )\n",
    "    assert session_after.user_profile_instructions == profile_after.system_instructions, (\n",
    "        \"Expected session snapshot to match persisted UserProfile.system_instructions.\"\n",
    "    )\n",
    "\n",
    "    # Ensure history integrity (history is stored in SessionStorage, not on ChatSession)\n",
    "    messages = await effective_session_manager.get_history_for_session(session_id=SESSION_ID)\n",
    "    roles = [m.role for m in messages]\n",
    "    assert all(r in (\"user\", \"assistant\") for r in roles), (\n",
    "        \"History integrity violated: only user/assistant roles must be persisted.\"\n",
    "    )\n",
    "\n",
    "    # Output\n",
    "    print(\"REFRESH OK\")\n",
    "    print(\"- session snapshot updated via get_user_profile_instructions_for_session(session)\")\n",
    "    print(\"- refresh flag cleared\")\n",
    "    print(\"- history unchanged (user/assistant only)\")\n",
    "    print(\"- snapshot value:\")\n",
    "    print(session_after.user_profile_instructions)\n",
    "\n",
    "\n",
    "await _refresh_and_validate_snapshot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd0f06",
   "metadata": {},
   "source": [
    "## Notebook 08 — Final Summary\n",
    "\n",
    "This notebook demonstrated a **complete, production-safe flow** for generating\n",
    "`UserProfile.system_instructions` using an LLM, while preserving a strict\n",
    "separation of responsibilities across the Intergrax architecture.\n",
    "\n",
    "### What was implemented and validated\n",
    "\n",
    "1) **Explicit profile consolidation flow**\n",
    "- Conversation history (user + assistant only) is used as input\n",
    "- Existing profile instructions are included as context\n",
    "- An LLM generates normalized system instructions\n",
    "- The result is persisted as domain data on `UserProfile`\n",
    "\n",
    "2) **Session refresh contract**\n",
    "- The session is explicitly marked with `needs_user_instructions_refresh = True`\n",
    "- Refresh happens lazily via `SessionManager.get_user_profile_instructions_for_session(session)`\n",
    "- A new per-session snapshot is cached and used by runtime\n",
    "- The refresh flag is cleared automatically\n",
    "\n",
    "3) **Runtime isolation preserved**\n",
    "- Runtime code was not modified\n",
    "- No LLM calls occur inside `ask()`\n",
    "- No system messages are persisted to conversation history\n",
    "- Instruction precedence rules remain unchanged\n",
    "\n",
    "### What this notebook did NOT do\n",
    "\n",
    "- No RAG\n",
    "- No tools\n",
    "- No websearch\n",
    "- No chain-of-thought\n",
    "- No org-profile conflicts\n",
    "- No runtime heuristics or feature flags\n",
    "\n",
    "### Architectural guarantees\n",
    "\n",
    "- Instruction generation is **auditable, testable, and deterministic**\n",
    "- Runtime behavior remains **clean, minimal, and predictable**\n",
    "- The system behaves in a **ChatGPT-like** manner:\n",
    "  instructions are stable profile data, not emergent runtime artifacts\n",
    "\n",
    "### Next logical steps (outside this notebook)\n",
    "\n",
    "- Conflict resolution: user vs organization instructions\n",
    "- Scheduling and cooldown policies for consolidation\n",
    "- Multi-pass or layered instruction generation\n",
    "- Optional RAG-assisted enrichment of profile instructions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
