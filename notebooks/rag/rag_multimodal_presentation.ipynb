{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410f38d4",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Integrax framework - proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e629794",
   "metadata": {},
   "source": [
    "# Load documents + split + embed + VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11233f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intergrax.rag.documents_loader import DocumentsLoader\n",
    "from intergrax.llm_adapters import LangChainOllamaAdapter\n",
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "# Ścieżki do plików testowych\n",
    "vid_path = os.path.join(\"video\", \"video02\", \"vid_eur8dUO9mvE.mp4\")\n",
    "audio_path = \"\" #os.path.join(\"video\", \"video02\", \"audio_eur8dUO9mvE.mp3\")\n",
    "image_path = \"\" #os.path.join(\"images\", \"frame_37.jpg\")\n",
    "\n",
    "\n",
    "ollama_adapter = LangChainOllamaAdapter(\n",
    "    chat=ChatOllama(\n",
    "        model=\"llava-llama3:latest\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "loader = DocumentsLoader(\n",
    "    verbose=True,\n",
    "    image_text_mode=\"both\",\n",
    "    image_caption_llm=ollama_adapter\n",
    ")\n",
    "\n",
    "if vid_path:\n",
    "    vid_docs = loader.load_document(file_path=vid_path)\n",
    "else:\n",
    "    vid_docs = []\n",
    "\n",
    "if audio_path:\n",
    "    audio_docs = loader.load_document(file_path=audio_path)\n",
    "else:\n",
    "    audio_docs = []\n",
    "\n",
    "if image_path:\n",
    "    image_docs = loader.load_document(file_path=image_path)\n",
    "else:\n",
    "    image_docs = []\n",
    "\n",
    "\n",
    "print(f\"Video docs: {len(vid_docs)}\")\n",
    "print(f\"Audio docs: {len(audio_docs)}\")\n",
    "print(f\"Image docs: {len(image_docs)}\")\n",
    "\n",
    "if image_docs:\n",
    "    print(\"\\n--- IMAGE CAPTION OUTPUT ---\")\n",
    "    print(image_docs[0].page_content[:500])\n",
    "    print(\"\\nMetadata:\", image_docs[0].metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49897d",
   "metadata": {},
   "source": [
    "# Split and embed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intergrax.rag.documents_splitter import DocumentsSplitter\n",
    "from intergrax.rag.embedding_manager import EmbeddingManager\n",
    "\n",
    "splitter = DocumentsSplitter(verbose=True)\n",
    "chunks = splitter.split_documents(documents=vid_docs+audio_docs+image_docs)\n",
    "\n",
    "embed_manager = EmbeddingManager(\n",
    "    verbose=True,\n",
    "    provider=\"ollama\",\n",
    "    model_name=\"rjmalagon/gte-qwen2-1.5b-instruct-embed-f16:latest\", \n",
    "    assume_ollama_dim=1536)\n",
    "\n",
    "embeddings, documents = embed_manager.embed_documents(docs=chunks)\n",
    "print(f\"Embeddings: {len(embeddings)}\")\n",
    "print(documents[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689cce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intergrax.rag.embedding_manager import EmbeddingManager\n",
    "from intergrax.rag.vectorstore_manager import VectorstoreManager, VSConfig\n",
    "from intergrax.rag.documents_splitter import DocumentsSplitter\n",
    "from intergrax.rag.documents_loader import DocumentsLoader\n",
    "from langchain_core.documents import Document\n",
    "from collections import Counter\n",
    "\n",
    "TENANT = \"intergrax\"\n",
    "CORPUS = \"intergrax-multimodal\"\n",
    "VERSION = \"v1\"\n",
    "\n",
    "# 0) Vectorstore na starcie (bez ładowania/splita/embedu)\n",
    "cfg = VSConfig(\n",
    "    provider=\"chroma\",\n",
    "    collection_name=\"multimodal_docs\",\n",
    "    chroma_persist_directory=\"chroma_db/multimodal_docs_v1\",\n",
    ")\n",
    "store = VectorstoreManager(config=cfg, verbose=True)\n",
    "\n",
    "def corpus_present(store: VectorstoreManager, embed_mgr: EmbeddingManager) -> bool:\n",
    "    if store.count() == 0:\n",
    "        return False\n",
    "    qvec = embed_mgr.embed_one(\"probe\")\n",
    "    \n",
    "    where = {\n",
    "        \"$and\": [\n",
    "            {\"tenant\": {\"$eq\": TENANT}},\n",
    "            {\"corpus\": {\"$eq\": CORPUS}},\n",
    "            {\"version\": {\"$eq\": VERSION}},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    res = store.query(query_embeddings=qvec, top_k=1, where=where)\n",
    "    return bool(res[\"ids\"] and res[\"ids\"][0])\n",
    "\n",
    "NEED_INGEST = not corpus_present(store, embed_manager)\n",
    "print(f\"Need ingest: {NEED_INGEST}\")\n",
    "\n",
    "if not NEED_INGEST:\n",
    "    print(\"[INGEST] Skipping — corpus already present.\")\n",
    "else:\n",
    "    doc_loader = DocumentsLoader(verbose=False)\n",
    "\n",
    "    def add_meta(chunk_doc: Document, idx: int, total: int):\n",
    "        return {\"tenant\": TENANT, \"corpus\": CORPUS, \"version\": VERSION}\n",
    "    \n",
    "    ids = []\n",
    "    for d in documents:\n",
    "        cid = d.metadata.get(\"chunk_id\")\n",
    "        if not cid:\n",
    "            parent = d.metadata.get(\"parent_id\") or d.metadata.get(\"source_path\") or d.metadata.get(\"source_name\", \"doc\")\n",
    "            idx = int(d.metadata.get(\"chunk_index\", 0))\n",
    "            cid = f\"{parent}#ch{idx:04d}\"\n",
    "        ids.append(cid)\n",
    "\n",
    "    def dedup_batch(ids, docs, embs):\n",
    "        seen = set()\n",
    "        new_ids, new_docs, new_embs = [], [], []\n",
    "        for i, _id in enumerate(ids):\n",
    "            if _id in seen:\n",
    "                continue\n",
    "            seen.add(_id)\n",
    "            new_ids.append(_id)\n",
    "            new_docs.append(docs[i])\n",
    "            new_embs.append(embs[i])\n",
    "        return new_ids, new_docs, new_embs\n",
    "\n",
    "    ids, documents, embeddings = dedup_batch(ids, documents, embeddings)\n",
    "\n",
    "    c = Counter(ids)\n",
    "    dups = [k for k, v in c.items() if v > 1]\n",
    "    if dups:\n",
    "        print(f\"[WARN] Duplicate IDs after dedup? {len(dups)}\")\n",
    "\n",
    "    base_metadata = {\"tenant\": TENANT, \"corpus\": CORPUS, \"version\": VERSION}\n",
    "    store.add_documents(\n",
    "        documents=documents,\n",
    "        embeddings=embeddings,\n",
    "        ids=ids,\n",
    "        batch_size=128,\n",
    "        base_metadata=base_metadata\n",
    "    )\n",
    "    print(\"[INGEST] Vectorstore updated. Count:\", store.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df875c97",
   "metadata": {},
   "source": [
    "# Retriever test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intergrax.rag.rag_retriever import RagRetriever\n",
    "from intergrax.multimedia.ipynb_display import display_audio_at_data, display_image, display_video_jump\n",
    "from IPython.display import display, Image, HTML\n",
    "from pathlib import Path\n",
    "\n",
    "retriever = RagRetriever(store, embed_manager, verbose=True)\n",
    "\n",
    "question = \"Men writting on the table 'mcp host'\"\n",
    "\n",
    "# MMR\n",
    "hits = retriever.retrieve(\n",
    "    question=question,\n",
    "    top_k=8,\n",
    "    score_threshold=0.15,\n",
    "    where={\"tenant\": TENANT, \"corpus\": CORPUS, \"version\": VERSION},\n",
    "    max_per_parent=2,\n",
    "    use_mmr=True,\n",
    "    include_embeddings=True,\n",
    "    prefetch_factor=5\n",
    ")\n",
    "\n",
    "\n",
    "for h in hits:\n",
    "    meta = h.get(\"metadata\", {})\n",
    "    print(h[\"rank\"], f\"{h['similarity_score']:.3f}\", meta)\n",
    "    print(h[\"content\"])\n",
    "\n",
    "    if meta.get(\"source_type\") == \"audio\" and os.path.exists(meta.get(\"source_path\",\"\")):        \n",
    "        start_s = meta.get(\"start_s\")\n",
    "        if start_s is None and meta.get(\"start_ms\") is not None:\n",
    "            start_s = float(meta[\"start_ms\"]) / 1000.0\n",
    "        if start_s is None:\n",
    "            start_s = 0.0\n",
    "\n",
    "        print(h[\"rank\"], f\"{h['similarity_score']:.3f}\", meta.get(\"source_name\"))\n",
    "        print(h[\"content\"])\n",
    "        display_audio_at_data( \n",
    "            path=meta[\"source_path\"],\n",
    "            start_s=float(start_s or 0.0),\n",
    "            autoplay=False,\n",
    "            label=f\"start @ {float(start_s or 0.0):.2f}s\"\n",
    "        )\n",
    "        print()\n",
    "        continue\n",
    "    \n",
    "    if meta.get(\"doc_type\") == \"video\" and meta.get(\"video_path\"):\n",
    "        start_s = float((meta.get(\"mid_time_ms\") or meta.get(\"start_ms\") or 0) / 1000.0)\n",
    "        dur_s   = float((meta.get(\"duration_ms\") or 6000) / 1000.0)\n",
    "        display_video_jump(\n",
    "            path=meta[\"video_path\"],\n",
    "            start_s=float((meta.get(\"mid_time_ms\") or meta.get(\"start_ms\") or 0)/1000.0),\n",
    "            # duration_s=float((meta.get(\"duration_ms\") or 6000)/1000.0),\n",
    "            poster=meta.get(\"extracted_frame_path\"),\n",
    "            autoplay=False,\n",
    "            muted=False,\n",
    "            label=f\"jump @ { (meta.get('mid_time_ms') or meta.get('start_ms') or 0)/1000:.2f}s (segment #{meta.get('video_segment_id')})\"\n",
    "        )\n",
    "        print()\n",
    "        continue\n",
    "\n",
    "    display_image(meta.get(\"source_path\"))\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
