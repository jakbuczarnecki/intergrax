{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed35e26",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Integrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2180ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "What is the weather in Warsaw?\n",
      "[intergraxChatAgent] ROUTE=tools RAG=-\n",
      "[intergraxToolsAgent] Iteration 1 (planner)\n",
      "[intergraxToolsAgent] Calling tool: get_weather({'city': 'Warsaw'})\n",
      "[intergraxToolsAgent] Iteration 2 (planner)\n",
      "Routing Decision:  tools\n",
      "RAG Component:  None\n",
      "Tool Triggered:  [{'tool': 'get_weather', 'args': {'city': 'Warsaw'}, 'output_preview': '{\"city\": \"Warsaw\", \"tempC\": 12.3, \"summary\": \"Partly cloudy\"}', 'output': {'city': 'Warsaw', 'tempC': 12.3, 'summary': 'Partly cloudy'}}]\n",
      "Final Answer:  The current weather in Warsaw is Partly cloudy with a temperature of 12.3 degrees Celsius.\n",
      "=============================================\n",
      "Explain in detail what Mooff virtual fairs are.\n",
      "[intergraxChatAgent] ROUTE=general RAG=-\n",
      "Routing Decision:  general\n",
      "RAG Component:  None\n",
      "Tool Triggered:  []\n",
      "Final Answer:  Moof Virtual Fairs are online events that allow exhibitors to showcase their products, services, and experiences in a virtual environment. They are designed to mimic the experience of traditional trade shows and exhibitions, but with the added benefits of being completely digital.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Virtual Booths:** Exhibitors create their own virtual booths, which can include text, images, videos, and interactive elements.\n",
      "2. **Product Showcase:** Companies showcase their products or services in a 3D environment, allowing attendees to explore and interact with them in detail.\n",
      "3. **Networking Opportunities:** Attendees can connect with exhibitors through live chat, video conferencing, or email, facilitating networking and business opportunities.\n",
      "4. **Interactive Content:** Exhibitors can share interactive content such as presentations, demos, and gamification elements to engage attendees.\n",
      "5. **Virtual Tours:** Some Moof Virtual Fairs include virtual tours of exhibition halls, allowing attendees to explore the event at their own pace.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Increased Reach:** Virtual fairs allow exhibitors to reach a global audience, reducing geographical barriers.\n",
      "2. **Cost-Effective:** No travel or accommodation costs for attendees or exhibitors.\n",
      "3. **Flexibility:** Attendees can access the virtual fair from anywhere and at any time.\n",
      "4. **Data Collection:** Exhibitors can collect valuable data on attendee engagement and interests.\n",
      "\n",
      "**Types of Moof Virtual Fairs:**\n",
      "\n",
      "1. **Product Launches:** Companies use Moof to launch new products or services, generating buzz and interest among attendees.\n",
      "2. **Industry Conferences:** Virtual fairs are used as a platform for industry conferences, allowing attendees to connect with experts and peers.\n",
      "3. **Trade Shows:** Traditional trade shows are adapted into virtual formats, providing exhibitors with a cost-effective way to showcase their products.\n",
      "\n",
      "**Target Audience:**\n",
      "\n",
      "1. **Business Professionals:** Attendees include business professionals looking to network, learn about new products or services, and establish partnerships.\n",
      "2. **Industry Experts:** Industry experts use Moof Virtual Fairs as a platform to share knowledge, showcase innovations, and connect with peers.\n",
      "\n",
      "Overall, Moof Virtual Fairs offer a unique opportunity for exhibitors to connect with attendees in a virtual environment, providing benefits such as increased reach, cost-effectiveness, flexibility, and data collection.\n",
      "=============================================\n",
      "Calculate 22 * 3 and provide just the result.\n",
      "[intergraxChatAgent] ROUTE=tools RAG=-\n",
      "[intergraxToolsAgent] Iteration 1 (planner)\n",
      "Routing Decision:  tools\n",
      "RAG Component:  None\n",
      "Tool Triggered:  []\n",
      "Final Answer:  66\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "from intergrax.globals.settings import GlobalSettings\n",
    "from intergrax.llm_adapters.llm_provider import LLMAdapterRegistry, LLMProvider\n",
    "from intergrax.llm_adapters.llm_usage_track import LLMUsageTracker\n",
    "import intergrax.system_prompts as prompts\n",
    "from intergrax.rag.embedding_manager import EmbeddingManager\n",
    "from intergrax.rag.rag_retriever import RagRetriever\n",
    "from intergrax.rag.rag_answerer import RagAnswerer, AnswererConfig\n",
    "from intergrax.memory.conversational_memory import ConversationalMemory\n",
    "from intergrax.tools.tools_base import ToolRegistry, ToolBase\n",
    "from intergrax.rag.vectorstore_manager import VSConfig, VectorstoreManager\n",
    "from intergrax.rag.re_ranker import ReRankerConfig, ReRanker\n",
    "from intergrax.chat_agent import ChatAgentConfig, RagComponent, ChatAgent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1) LLM + conversational memory\n",
    "# -----------------------------------------------------------\n",
    "llm = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "memory = ConversationalMemory()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2) Example Tool: Weather\n",
    "# -----------------------------------------------------------\n",
    "class WeatherArgs(BaseModel):\n",
    "    \"\"\"Arguments required to call the weather tool.\"\"\"\n",
    "    city: str = Field(..., description=\"City name. Example: 'Warsaw'.\")\n",
    "\n",
    "\n",
    "class WeatherTool(ToolBase):\n",
    "    \"\"\"\n",
    "    Demo weather tool that simulates a weather API response.\n",
    "\n",
    "    Used by the agent when the user requests weather information.\n",
    "    \"\"\"\n",
    "    name = \"get_weather\"\n",
    "    description = (\n",
    "        \"Returns the current weather for a given city. Use only for queries \"\n",
    "        \"related to weather, temperature or atmospheric conditions.\"\n",
    "    )\n",
    "    schema_model = WeatherArgs\n",
    "\n",
    "    def run(self, **kwargs):\n",
    "        city = kwargs[\"city\"]\n",
    "        # Static demo response.\n",
    "        return {\"city\": city, \"tempC\": 12.3, \"summary\": \"Partly cloudy\"}\n",
    "\n",
    "\n",
    "# Register available tools\n",
    "tools = ToolRegistry()\n",
    "tools.register(WeatherTool())\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3) Vector store & RAG configuration\n",
    "# -----------------------------------------------------------\n",
    "cfg = VSConfig(\n",
    "    provider=\"chroma\",\n",
    "    collection_name=\"intergrax_docs\",\n",
    "    chroma_persist_directory=\"chroma_db/intergrax_docs_v1\",\n",
    ")\n",
    "\n",
    "store = VectorstoreManager(config=cfg, verbose=False)\n",
    "\n",
    "embed_manager = EmbeddingManager(\n",
    "    verbose=False,\n",
    "    provider=\"ollama\",\n",
    "    model_name=GlobalSettings.default_ollama_embed_model,\n",
    "    assume_ollama_dim=1536,\n",
    ")\n",
    "\n",
    "reranker = ReRanker(\n",
    "    embedding_manager=embed_manager,\n",
    "    config=ReRankerConfig(\n",
    "        use_score_fusion=True,\n",
    "        fusion_alpha=0.4,\n",
    "        normalize=\"minmax\",\n",
    "        doc_batch_size=256,\n",
    "    ),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "retriever = RagRetriever(store, embed_manager, verbose=False)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4) RAG Answerer configuration\n",
    "# -----------------------------------------------------------\n",
    "cfg = AnswererConfig(\n",
    "    top_k=10,\n",
    "    min_score=0.15,\n",
    "    re_rank_k=5,\n",
    "    max_context_chars=12000,\n",
    ")\n",
    "\n",
    "cfg.system_instructions = prompts.default_rag_system_instruction()\n",
    "cfg.system_context_template = (\n",
    "    \"Use the following retrieved context to answer the user question: {context}\"\n",
    ")\n",
    "\n",
    "answerer_docs = RagAnswerer(\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    reranker=reranker,\n",
    "    config=cfg,\n",
    "    memory=None,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# RAG routing logic description\n",
    "rag_docs = RagComponent(\n",
    "    name=\"intergrax_docs\",\n",
    "    answerer=answerer_docs,\n",
    "    description=(\n",
    "        \"This component responds to questions related to Mooff regulations, \"\n",
    "        \"privacy policies, internal documentation, and compliance rules. \"\n",
    "        \"Use this component for legally-bound questions or factual document-based queries.\"\n",
    "    ),\n",
    "    priority=10,\n",
    ")\n",
    "\n",
    "usage_tracker = LLMUsageTracker(run_id=\"test\")\n",
    "usage_tracker.register_adapter(llm)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5) High-level hybrid agent (RAG + tools + LLM chat)\n",
    "# -----------------------------------------------------------\n",
    "agent = ChatAgent(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    tools=tools,\n",
    "    rag_components=[rag_docs],\n",
    "    config=ChatAgentConfig(verbose=True),\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6) Test Questions\n",
    "# -----------------------------------------------------------\n",
    "for question in [\n",
    "    \"What is the weather in Warsaw?\",\n",
    "    \"Explain in detail what Mooff virtual fairs are.\",\n",
    "    \"Calculate 22 * 3 and provide just the result.\",\n",
    "]:\n",
    "    print(question)\n",
    "    \n",
    "    response = agent.run(question=question, run_id=usage_tracker.run_id)\n",
    "    \n",
    "    print(\"Routing Decision: \", response[\"route\"])\n",
    "    print(\"RAG Component: \", response[\"rag_component\"])\n",
    "    print(\"Tool Triggered: \", response[\"tool_traces\"])\n",
    "    print(\"Final Answer: \", response[\"answer\"])\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31385961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Adapters==========\n",
      "950a839e95d14813acb2d185ea3c46b0\n",
      "\n",
      "\n",
      "==========Total==========\n",
      "calls: 0\n",
      "input_tokens: 0\n",
      "output_tokens: 0\n",
      "total_tokens: 0\n",
      "duration_ms: 0\n",
      "errors: 0\n"
     ]
    }
   ],
   "source": [
    "from intergrax.llm_adapters.llm_adapter import LLMRunStats\n",
    "\n",
    "\n",
    "print(\"==========Adapters==========\")\n",
    "for label in usage_tracker.registered_labels():\n",
    "    print(label)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"==========Total==========\")\n",
    "total:LLMRunStats = usage_tracker.total();\n",
    "print(f\"calls: {total.calls}\")\n",
    "print(f\"input_tokens: {total.input_tokens}\")\n",
    "print(f\"output_tokens: {total.output_tokens}\")\n",
    "print(f\"total_tokens: {total.total_tokens}\")\n",
    "print(f\"duration_ms: {total.duration_ms}\")\n",
    "print(f\"errors: {total.errors}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
