{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed35e26",
   "metadata": {},
   "source": [
    "# © Artur Czarnecki. All rights reserved.\n",
    "# Integrax framework – proprietary and confidential.\n",
    "# Use, modification, or distribution without written permission is prohibited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2180ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\genai_longchain\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "What is the weather in Warsaw?\n",
      "[intergraxChatAgent] ROUTE=tools RAG=-\n",
      "[intergraxToolsAgent] Iteration 1 (planner)\n",
      "[intergraxToolsAgent] Calling tool: get_weather({'city': 'Warsaw'})\n",
      "[intergraxToolsAgent] Iteration 2 (planner)\n",
      "Routing Decision:  tools\n",
      "RAG Component:  None\n",
      "Tool Triggered:  [{'tool': 'get_weather', 'args': {'city': 'Warsaw'}, 'output_preview': '{\"city\": \"Warsaw\", \"tempC\": 12.3, \"summary\": \"Partly cloudy\"}', 'output': {'city': 'Warsaw', 'tempC': 12.3, 'summary': 'Partly cloudy'}}]\n",
      "Final Answer:  The current weather in Warsaw is Partly cloudy with a temperature of 12.3 degrees Celsius.\n",
      "=============================================\n",
      "Explain in detail what Mooff virtual fairs are.\n",
      "[intergraxChatAgent] ROUTE=general RAG=-\n",
      "Routing Decision:  general\n",
      "RAG Component:  None\n",
      "Tool Triggered:  []\n",
      "Final Answer:  Moof Virtual Fairs are online events that allow exhibitors to showcase their products, services, and experiences in a virtual environment. These fairs aim to replicate the experience of traditional trade shows, conferences, and exhibitions, but with the added benefits of digital accessibility and flexibility.\n",
      "\n",
      "Here's how Moof Virtual Fairs work:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Virtual Booths:** Exhibitors create their own virtual booths, which can be customized with branding, graphics, and multimedia content.\n",
      "2. **Interactive Experiences:** Visitors can engage with exhibitors through live chat, video conferencing, or interactive presentations.\n",
      "3. **Product Demonstrations:** Companies can showcase their products in 360-degree views, allowing visitors to explore and interact with them remotely.\n",
      "4. **Networking Opportunities:** Attendees can connect with other attendees, speakers, and sponsors through a built-in networking platform.\n",
      "5. **Content Library:** Moof Virtual Fairs offer a content library where exhibitors can upload videos, presentations, and documents for visitors to access.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Increased Reach:** Virtual fairs allow companies to reach a global audience, reducing the need for travel and increasing accessibility.\n",
      "2. **Cost-Effective:** Exhibiting at virtual fairs is often more cost-effective than traditional trade shows, with lower costs for booth design, logistics, and travel.\n",
      "3. **Data Collection:** Moof Virtual Fairs provide valuable insights into attendee behavior, allowing exhibitors to track engagement and measure the effectiveness of their marketing efforts.\n",
      "4. **Sustainability:** By reducing the need for physical events, virtual fairs contribute to a more sustainable approach to business-to-business (B2B) marketing.\n",
      "\n",
      "**Target Audience:**\n",
      "\n",
      "Moof Virtual Fairs cater to various industries, including:\n",
      "\n",
      "1. Technology\n",
      "2. Healthcare\n",
      "3. Manufacturing\n",
      "4. Education\n",
      "5. Finance\n",
      "\n",
      "These events are ideal for companies looking to connect with professionals, showcase their products or services, and build relationships in a virtual environment.\n",
      "\n",
      "Overall, Moof Virtual Fairs offer a unique opportunity for businesses to engage with their target audience, increase brand awareness, and drive sales leads in a cost-effective and sustainable way.\n",
      "=============================================\n",
      "Calculate 22 * 3 and provide just the result.\n",
      "[intergraxChatAgent] ROUTE=tools RAG=-\n",
      "[intergraxToolsAgent] Iteration 1 (planner)\n",
      "Routing Decision:  tools\n",
      "RAG Component:  None\n",
      "Tool Triggered:  []\n",
      "Final Answer:  66\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Optional\n",
    "from intergrax.globals.settings import GlobalSettings\n",
    "from intergrax.llm_adapters.llm_provider import LLMProvider\n",
    "from intergrax.llm_adapters.llm_provider_registry import LLMAdapterRegistry\n",
    "from intergrax.llm_adapters.llm_usage_track import LLMUsageTracker\n",
    "import intergrax.system_prompts as prompts\n",
    "from intergrax.rag.embedding_manager import EmbeddingManager\n",
    "from intergrax.rag.rag_retriever import RagRetriever\n",
    "from intergrax.rag.rag_answerer import RagAnswerer, AnswererConfig\n",
    "from intergrax.memory.conversational_memory import ConversationalMemory\n",
    "from intergrax.tools.tools_base import ToolRegistry, ToolBase\n",
    "from intergrax.rag.vectorstore_manager import VSConfig, VectorstoreManager\n",
    "from intergrax.rag.re_ranker import ReRankerConfig, ReRanker\n",
    "from intergrax.chat_agent import ChatAgentConfig, RagComponent, ChatAgent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1) LLM + conversational memory\n",
    "# -----------------------------------------------------------\n",
    "llm = LLMAdapterRegistry.create(LLMProvider.OLLAMA)\n",
    "memory = ConversationalMemory()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2) Example Tool: Weather\n",
    "# -----------------------------------------------------------\n",
    "class WeatherArgs(BaseModel):\n",
    "    \"\"\"Arguments required to call the weather tool.\"\"\"\n",
    "    city: str = Field(..., description=\"City name. Example: 'Warsaw'.\")\n",
    "\n",
    "\n",
    "class WeatherTool(ToolBase):\n",
    "    \"\"\"\n",
    "    Demo weather tool that simulates a weather API response.\n",
    "\n",
    "    Used by the agent when the user requests weather information.\n",
    "    \"\"\"\n",
    "    name = \"get_weather\"\n",
    "    description = (\n",
    "        \"Returns the current weather for a given city. Use only for queries \"\n",
    "        \"related to weather, temperature or atmospheric conditions.\"\n",
    "    )\n",
    "    schema_model = WeatherArgs\n",
    "\n",
    "    def run(self, \n",
    "            run_id:Optional[str] = None,\n",
    "            llm_usage_tracker: Optional[LLMUsageTracker] = None,\n",
    "            **kwargs) -> Any:\n",
    "        city = kwargs[\"city\"]\n",
    "        # Static demo response.\n",
    "        return {\"city\": city, \"tempC\": 12.3, \"summary\": \"Partly cloudy\"}\n",
    "\n",
    "\n",
    "# Register available tools\n",
    "tools = ToolRegistry()\n",
    "tools.register(WeatherTool())\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3) Vector store & RAG configuration\n",
    "# -----------------------------------------------------------\n",
    "cfg = VSConfig(\n",
    "    provider=\"chroma\",\n",
    "    collection_name=\"intergrax_docs\",\n",
    "    chroma_persist_directory=\"chroma_db/intergrax_docs_v1\",\n",
    ")\n",
    "\n",
    "store = VectorstoreManager(config=cfg, verbose=False)\n",
    "\n",
    "embed_manager = EmbeddingManager(\n",
    "    verbose=False,\n",
    "    provider=\"ollama\",\n",
    "    model_name=GlobalSettings.default_ollama_embed_model,\n",
    "    assume_ollama_dim=1536,\n",
    ")\n",
    "\n",
    "reranker = ReRanker(\n",
    "    embedding_manager=embed_manager,\n",
    "    config=ReRankerConfig(\n",
    "        use_score_fusion=True,\n",
    "        fusion_alpha=0.4,\n",
    "        normalize=\"minmax\",\n",
    "        doc_batch_size=256,\n",
    "    ),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "retriever = RagRetriever(store, embed_manager, verbose=False)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4) RAG Answerer configuration\n",
    "# -----------------------------------------------------------\n",
    "cfg = AnswererConfig(\n",
    "    top_k=10,\n",
    "    min_score=0.15,\n",
    "    re_rank_k=5,\n",
    "    max_context_chars=12000,\n",
    ")\n",
    "\n",
    "cfg.system_instructions = prompts.default_rag_system_instruction()\n",
    "cfg.system_context_template = (\n",
    "    \"Use the following retrieved context to answer the user question: {context}\"\n",
    ")\n",
    "\n",
    "answerer_docs = RagAnswerer(\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    reranker=reranker,\n",
    "    config=cfg,\n",
    "    memory=None,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# RAG routing logic description\n",
    "rag_docs = RagComponent(\n",
    "    name=\"intergrax_docs\",\n",
    "    answerer=answerer_docs,\n",
    "    description=(\n",
    "        \"This component responds to questions related to Mooff regulations, \"\n",
    "        \"privacy policies, internal documentation, and compliance rules. \"\n",
    "        \"Use this component for legally-bound questions or factual document-based queries.\"\n",
    "    ),\n",
    "    priority=10,\n",
    ")\n",
    "\n",
    "usage_tracker = LLMUsageTracker(run_id=\"test\")\n",
    "usage_tracker.register_adapter(llm)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5) High-level hybrid agent (RAG + tools + LLM chat)\n",
    "# -----------------------------------------------------------\n",
    "agent = ChatAgent(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    tools=tools,\n",
    "    rag_components=[rag_docs],\n",
    "    config=ChatAgentConfig(verbose=True),\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6) Test Questions\n",
    "# -----------------------------------------------------------\n",
    "for question in [\n",
    "    \"What is the weather in Warsaw?\",\n",
    "    \"Explain in detail what Mooff virtual fairs are.\",\n",
    "    \"Calculate 22 * 3 and provide just the result.\",\n",
    "]:\n",
    "    print(question)\n",
    "    \n",
    "    response = agent.run(question=question, run_id=usage_tracker.run_id)\n",
    "    \n",
    "    print(\"Routing Decision: \", response[\"route\"])\n",
    "    print(\"RAG Component: \", response[\"rag_component\"])\n",
    "    print(\"Tool Triggered: \", response[\"tool_traces\"])\n",
    "    print(\"Final Answer: \", response[\"answer\"])\n",
    "    print(\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31385961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Adapters==========\n",
      "9c0c1b5dcc2f4e86a63b6bb002ca754f\n",
      "\n",
      "\n",
      "==========Total==========\n",
      "calls: 4\n",
      "input_tokens: 2025\n",
      "output_tokens: 474\n",
      "total_tokens: 2499\n",
      "duration_ms: 14431\n",
      "errors: 0\n"
     ]
    }
   ],
   "source": [
    "from intergrax.llm_adapters.llm_adapter import LLMRunStats\n",
    "\n",
    "\n",
    "print(\"==========Adapters==========\")\n",
    "for label in usage_tracker.registered_labels():\n",
    "    print(label)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"==========Total==========\")\n",
    "total:LLMRunStats = usage_tracker.total();\n",
    "print(f\"calls: {total.calls}\")\n",
    "print(f\"input_tokens: {total.input_tokens}\")\n",
    "print(f\"output_tokens: {total.output_tokens}\")\n",
    "print(f\"total_tokens: {total.total_tokens}\")\n",
    "print(f\"duration_ms: {total.duration_ms}\")\n",
    "print(f\"errors: {total.errors}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_longchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
